# CNN and LSTM-based Speech Emotion Recognition with Data Augmentation Techniques

## Overview

The CNN-LSTM Speech Emotion Recognition project focuses on the task of recognizing human emotions from speech using a combination of Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) networks. Emotion recognition from speech has significant applications in areas like affective computing, human-computer interaction, and sentiment analysis.

## Jupyter Notebook Files

The project consists of the following Jupyter notebook files:

- 1-preprocess.ipynb: This notebook contains the preprocessing steps for preparing the speech data before feeding it into the CNN-LSTM model. It include tasks like loading the data, turning it into MFCCs vevtor
- 2-model_implementation_and_performance.ipynb: In this notebook, the CNN-LSTM and other CNN-based model is implemented and trained using the preprocessed data. The model's performance is evaluated on a test dataset by using evaluation metrics such as accuracy, F1-Score, Recall, Precision, and Confusion Matrix
- 3-augmentation.ipynb: This notebook focuses on data augmentation techniques. Data augmentation is useful to increase the diversity of the training data, which can help improve the model's generalization and robustness. The notebook cover techniques like pitch shifting, time stretching, and noise addition.

## Dataset

The jupyter notebook files on this project use CREMA-D Dataset as examples.

## Author's Note

if you want the complete version of the code, view the src folder (it's really disorganized).
