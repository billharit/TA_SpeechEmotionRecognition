{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook Gives a guideline on how to turn audio into MFCCs Vector. Note: This Notebook only shows code used for dataset CREMA-D AND DOES NOT USES CORRECT VARIABLES (Read the Markdown and Comment for each step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step by Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load to DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Following Cell is a function that takes 2 folder input of train and test. The function only work on CREMA-D Dataset because of file naming and uses split manually \n",
    "This Function Returns 2 DataFrame containing file path and target for each file in train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_dataframe(train_folder_path, test_folder_path):\n",
    "    \"\"\"\n",
    "    Loads train and test data from the specified file folders, and returns them as pandas DataFrame objects.\n",
    "    :param train_folder_path: The path to the folder containing the train data files.\n",
    "    :type train_folder_path: str\n",
    "    :param test_folder_path: The path to the folder containing the test data files.\n",
    "    :type test_folder_path: str\n",
    "    :return: A two pandas DataFrame objects, containing the train and test data, respectively.\n",
    "    :rtype: pandas.core.frame.DataFrame, pandas.core.frame.DataFrame\n",
    "    \"\"\"\n",
    "    train_path = 'dataset/train'\n",
    "    test_path = 'dataset/test'\n",
    "    train_dir_list = os.listdir(train_path)\n",
    "    test_dir_list = os.listdir(test_path)\n",
    "\n",
    "    train_sentiment_value = []\n",
    "    test_sentiment_value = []\n",
    "    train_file_path = []\n",
    "    test_file_path = []\n",
    "\n",
    "    for file in train_dir_list:\n",
    "        train_file_path.append(train_path + '/' + file)\n",
    "        sentiment_code = file.split('_')\n",
    "        if sentiment_code[2] == 'ANG':\n",
    "            train_sentiment_value.append('angry')\n",
    "        elif sentiment_code[2] == 'DIS':\n",
    "            train_sentiment_value.append('disgust')\n",
    "        elif sentiment_code[2] == 'FEA':\n",
    "            train_sentiment_value.append('fear')\n",
    "        elif sentiment_code[2] == 'HAP':\n",
    "            train_sentiment_value.append('happy')\n",
    "        elif sentiment_code[2] == 'NEU':\n",
    "            train_sentiment_value.append('neutral')\n",
    "        elif sentiment_code[2] == 'SAD':\n",
    "            train_sentiment_value.append('sad')\n",
    "        else:\n",
    "            train_sentiment_value.append('unknown')\n",
    "\n",
    "    for file in test_dir_list:\n",
    "        test_file_path.append(test_path + '/' + file)\n",
    "        sentiment_code = file.split('_')\n",
    "        if sentiment_code[2] == 'ANG':\n",
    "            test_sentiment_value.append('angry')\n",
    "        elif sentiment_code[2] == 'DIS':\n",
    "            test_sentiment_value.append('disgust')\n",
    "        elif sentiment_code[2] == 'FEA':\n",
    "            test_sentiment_value.append('fear')\n",
    "        elif sentiment_code[2] == 'HAP':\n",
    "            test_sentiment_value.append('happy')\n",
    "        elif sentiment_code[2] == 'NEU':\n",
    "            test_sentiment_value.append('neutral')\n",
    "        elif sentiment_code[2] == 'SAD':\n",
    "            test_sentiment_value.append('sad')\n",
    "        else:\n",
    "            test_sentiment_value.append('unknown')\n",
    "\n",
    "    train_sentiment_df = pd.DataFrame(\n",
    "        {\"File_Path\": train_file_path, \"Target\": train_sentiment_value})\n",
    "\n",
    "    test_sentiment_df = pd.DataFrame(\n",
    "        {\"File_Path\": test_file_path, \"Target\": test_sentiment_value})\n",
    "\n",
    "    return train_sentiment_df, test_sentiment_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn Audio Signal into MFCCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Setting up Variables and Initialazation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Variables for Constructing MFCCs\n",
    "num_mfcc = 40 # Number of MFCCS\n",
    "SAMPLE_RATE = 16000 # Set this for the desired sample rate, use None if want to use Native Sample Rate\n",
    "n_fft = 2048 # Length of FFT\n",
    "hop_length = 512 # Length of Hop_Length\n",
    "\n",
    "# For more info open Librosa MFCCs Documentation\n",
    "\n",
    "train_df = \"\" # Place the Train DataFrame returned from previous CELL here\n",
    "test_df = \"\" # Place the Test DataFrame returned from previous CELL here\n",
    "\n",
    "\n",
    "# Initialize 2 Dictionary of train and test value\n",
    "train_data = {\n",
    "    \"labels\": [],\n",
    "    \"mfcc\": []\n",
    "}\n",
    "\n",
    "test_data = {\n",
    "    \"labels\": [],\n",
    "    \"mfcc\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Encode Categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following Labels is get from previous step on turning the data into data frame\n",
    "labels = {'disgust': 0, 'happy': 1, 'sad': 2,\n",
    "            'neutral': 3, 'fear': 4, 'angry': 5}\n",
    "train_df_encoded = train_df.replace({'Target': labels}, inplace=False)\n",
    "test_df_encoded = test_df.replace({'Target': labels}, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Loop all data to Turn it into MFCCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code loop the train_df from previous process. To create the test set just replace all named \"train\" into \"test\"\n",
    "for item, row in train_df.iterrows():\n",
    "    train_data['labels'].append(train_df_encoded.iloc[item, 1])\n",
    "    signal, sample_rate = librosa.load(\n",
    "        train_df_encoded.iloc[item, 0], sr=SAMPLE_RATE)\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y=signal, sr=SAMPLE_RATE, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    \n",
    "    # Transpose the MFCCs (For more readable data)\n",
    "    mfcc = mfcc.T\n",
    "    train_data[\"mfcc\"].append(np.asarray(mfcc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Zero-padding and Saving the preprocessed data into numpy for easier load to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn it into numpy array \n",
    "train_data_value = np.asarray(train_data['mfcc'])\n",
    "train_data_target = np.asarray(train_data[\"labels\"])\n",
    "\n",
    "# Preprocess using TensorFlow \n",
    "# maxlen should be set on the longest value of the data (on the Frame Axis)\n",
    "# to check each data loop the train_data_value and use .shape to find the longest length.\n",
    "# maxLength = max(len(x) for x in train_data_value)\n",
    "# The commented line above can be used to find the maximum length from the train_data_value\n",
    "train_data_value = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    train_data_value, maxlen=156, dtype=\"float32\")\n",
    "\n",
    "# Saving the dataset for easier load\n",
    "# this would create .npy file on your directory\n",
    "np.save(\"Crema-D_Train\", train_data_value)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
