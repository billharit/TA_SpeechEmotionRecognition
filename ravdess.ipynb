{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "folder_file = os.listdir(\"ravdess_dataset/audio_speech_actors_01-24\")\n",
    "for x in folder_file:\n",
    "    item_file = os.listdir(\"ravdess_dataset/audio_speech_actors_01-24/{}\".format(x))\n",
    "    for y in item_file:\n",
    "        data_list.append(\"ravdess_dataset/audio_speech_actors_01-24/{}/{}\".format(x,y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1440"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate_dataframe = pd.DataFrame(columns=[\"File_Name\", \"Sample_Rate\", \"Duration\"])\n",
    "for item in data_list:\n",
    "    sample_rate = librosa.get_samplerate(item)\n",
    "    duration = librosa.get_duration(path=item, sr=sample_rate)\n",
    "    new_row = {\"File_Name\": item,\"Sample_Rate\": sample_rate, \"Duration\": duration}\n",
    "    sample_rate_dataframe = pd.concat(\n",
    "            [sample_rate_dataframe, pd.DataFrame(new_row, index=[0])])\n",
    "sample_rate_dataframe = sample_rate_dataframe.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9362708333333334\n",
      "5.2719375\n",
      "3.7006648148148145\n",
      "48000    1440\n",
      "Name: Sample_Rate, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(sample_rate_dataframe.Duration.min())\n",
    "print(sample_rate_dataframe.Duration.max())\n",
    "print(sample_rate_dataframe.Duration.mean())\n",
    "print(sample_rate_dataframe.Sample_Rate.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {'disgust': 0, 'happy': 1, 'sad': 2,\n",
    "            'neutral': 3, 'fear': 4, 'angry': 5}\n",
    "data_sentiment_path = []\n",
    "data_sentiment_value = []\n",
    "data_sentiment_encoded_value = []\n",
    "for file in data_list:\n",
    "    sentiment_code = file[-18:-16]\n",
    "    if sentiment_code == '05':\n",
    "        data_sentiment_path.append(file)\n",
    "        data_sentiment_value.append('angry')  \n",
    "        data_sentiment_encoded_value.append(5)        \n",
    "    elif sentiment_code == '07':\n",
    "        data_sentiment_path.append(file)\n",
    "        data_sentiment_value.append('disgust')  \n",
    "        data_sentiment_encoded_value.append(0)\n",
    "    elif sentiment_code == '06':\n",
    "        data_sentiment_path.append(file)\n",
    "        data_sentiment_value.append('fear')  \n",
    "        data_sentiment_encoded_value.append(4)\n",
    "    elif sentiment_code == '03':\n",
    "        data_sentiment_path.append(file)\n",
    "        data_sentiment_value.append('happy')  \n",
    "        data_sentiment_encoded_value.append(1)\n",
    "    elif sentiment_code == '01':\n",
    "        data_sentiment_path.append(file)\n",
    "        data_sentiment_value.append('neutral')  \n",
    "        data_sentiment_encoded_value.append(3)\n",
    "    elif sentiment_code == '04':\n",
    "        data_sentiment_path.append(file)\n",
    "        data_sentiment_value.append('sad')  \n",
    "        data_sentiment_encoded_value.append(2)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_16024\\2681898832.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  processed_data_value = np.asarray(train_data['mfcc'])\n"
     ]
    }
   ],
   "source": [
    "num_mfcc = 40\n",
    "SAMPLE_RATE = 48000\n",
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "\n",
    "train_data = {\n",
    "    \"labels\": [],\n",
    "    \"mfcc\": []\n",
    "}\n",
    "\n",
    "for path, value in zip(data_sentiment_path, data_sentiment_encoded_value):\n",
    "    signal, sample_rate = librosa.load(path)\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y=signal, sr=SAMPLE_RATE, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    mfcc = mfcc.T\n",
    "\n",
    "    \n",
    "    train_data['labels'].append(value)\n",
    "    train_data[\"mfcc\"].append(np.asarray(mfcc))\n",
    "\n",
    "processed_data_value = np.asarray(train_data['mfcc'])\n",
    "processed_data_target = np.asarray(train_data[\"labels\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorToMFCC(vector):\n",
    "  vector.T\n",
    "  librosa.display.specshow(vector, hop_length=512)\n",
    "  plt.xlabel(\"Time\")\n",
    "  plt.ylabel(\"MFCC\")\n",
    "  plt.colorbar()\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[107], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m processed_data_value\n\u001b[1;32m----> 2\u001b[0m processed_data_value\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m]\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "processed_data_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_processed = []\n",
    "for x in processed_data_value:\n",
    "    shape_processed.append(x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160.82291666666666"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statistics import mean\n",
    "mean(shape_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_data_value = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    processed_data_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1056, 228, 40)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_data_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"ravdess_data-value\", padded_data_value)\n",
    "np.save(\"ravdess_data_target\", processed_data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (844, 228, 40)\n",
      "Shape of X_test: (212, 228, 40)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data_value, test_data_value, train_data_target, test_data_target = train_test_split(padded_data_value, processed_data_target, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[   0,    0,    0, ...,    0,    0,    0],\n",
       "        [   0,    0,    0, ...,    0,    0,    0],\n",
       "        [   0,    0,    0, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [-669,    0,    0, ...,    0,    0,    0],\n",
       "        [-669,    0,    0, ...,    0,    0,    0],\n",
       "        [-669,    0,    0, ...,    0,    0,    0]],\n",
       "\n",
       "       [[   0,    0,    0, ...,    0,    0,    0],\n",
       "        [   0,    0,    0, ...,    0,    0,    0],\n",
       "        [   0,    0,    0, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [-877,   13,   13, ...,    0,    0,    0],\n",
       "        [-879,   10,   10, ...,    0,    0,    0],\n",
       "        [-876,   14,   13, ...,    0,    0,    0]],\n",
       "\n",
       "       [[   0,    0,    0, ...,    0,    0,    0],\n",
       "        [   0,    0,    0, ...,    0,    0,    0],\n",
       "        [   0,    0,    0, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [-660,    0,    0, ...,    0,    0,    0],\n",
       "        [-659,    1,    1, ...,    1,    1,    1],\n",
       "        [-659,    1,    1, ...,    0,    0,    0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[   0,    0,    0, ...,    0,    0,    0],\n",
       "        [   0,    0,    0, ...,    0,    0,    0],\n",
       "        [   0,    0,    0, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [-541,   32,  -29, ...,    0,    4,    1],\n",
       "        [-525,   30,  -38, ...,   -1,   -2,   -1],\n",
       "        [-517,   32,  -36, ...,   -2,   -2,   -2]],\n",
       "\n",
       "       [[   0,    0,    0, ...,    0,    0,    0],\n",
       "        [   0,    0,    0, ...,    0,    0,    0],\n",
       "        [   0,    0,    0, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [-606,    0,    0, ...,    0,    0,    0],\n",
       "        [-606,    0,    0, ...,    0,    0,    0],\n",
       "        [-606,    0,    0, ...,    0,    0,    0]],\n",
       "\n",
       "       [[   0,    0,    0, ...,    0,    0,    0],\n",
       "        [   0,    0,    0, ...,    0,    0,    0],\n",
       "        [   0,    0,    0, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [-705,    0,    0, ...,    0,    0,    0],\n",
       "        [-705,    0,    0, ...,    0,    0,    0],\n",
       "        [-705,    0,    0, ...,    0,    0,    0]]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 1, 5, 2, 4, 1, 0, 5, 5, 5, 2, 4, 4, 2, 1, 0, 2, 2, 2, 3, 1,\n",
       "       4, 2, 0, 4, 1, 3, 0, 5, 1, 2, 3, 1, 1, 2, 0, 1, 3, 1, 5, 1, 0, 1,\n",
       "       5, 3, 5, 2, 4, 0, 4, 1, 4, 1, 2, 5, 1, 1, 4, 4, 4, 4, 5, 4, 5, 2,\n",
       "       3, 1, 5, 0, 5, 4, 0, 4, 3, 2, 2, 5, 1, 5, 2, 4, 2, 0, 5, 1, 4, 0,\n",
       "       0, 4, 4, 2, 4, 4, 0, 3, 0, 4, 2, 3, 0, 0, 0, 4, 1, 3, 1, 2, 1, 5,\n",
       "       1, 1, 0, 5, 2, 3, 5, 0, 2, 5, 0, 1, 4, 1, 4, 2, 5, 1, 1, 1, 5, 3,\n",
       "       0, 2, 1, 1, 2, 0, 4, 4, 0, 0, 1, 1, 5, 4, 3, 1, 0, 3, 1, 4, 2, 1,\n",
       "       1, 5, 1, 2, 3, 5, 2, 1, 2, 2, 4, 1, 1, 2, 1, 1, 0, 1, 5, 5, 5, 4,\n",
       "       1, 0, 1, 0, 0, 4, 2, 0, 2, 2, 5, 5, 0, 1, 3, 1, 3, 4, 3, 0, 0, 5,\n",
       "       3, 1, 4, 1, 4, 5, 1, 2, 1, 0, 0, 0, 0, 4, 4, 2, 3, 1, 1, 1, 1, 2,\n",
       "       5, 5, 5, 0, 0, 4, 2, 2, 5, 2, 5, 3, 3, 5, 4, 4, 0, 2, 5, 4, 0, 5,\n",
       "       0, 2, 1, 0, 1, 5, 2, 1, 4, 4, 0, 5, 2, 2, 2, 2, 3, 0, 2, 3, 0, 2,\n",
       "       1, 5, 1, 0, 1, 5, 5, 2, 4, 2, 0, 0, 4, 2, 0, 5, 2, 1, 2, 2, 1, 0,\n",
       "       4, 1, 4, 0, 4, 3, 0, 3, 2, 5, 0, 1, 0, 3, 3, 2, 5, 1, 2, 1, 0, 2,\n",
       "       2, 4, 1, 5, 1, 5, 2, 0, 4, 4, 5, 2, 4, 0, 2, 0, 5, 5, 3, 4, 5, 3,\n",
       "       1, 1, 3, 1, 0, 4, 5, 4, 4, 2, 0, 5, 5, 1, 0, 5, 2, 2, 2, 4, 3, 3,\n",
       "       1, 0, 5, 1, 1, 2, 3, 4, 4, 4, 4, 5, 4, 1, 0, 5, 2, 5, 0, 0, 5, 4,\n",
       "       1, 1, 1, 2, 1, 2, 3, 4, 4, 2, 4, 4, 2, 0, 4, 4, 1, 2, 4, 4, 5, 2,\n",
       "       1, 3, 0, 2, 2, 4, 1, 0, 0, 5, 3, 0, 0, 4, 0, 1, 2, 0, 5, 2, 1, 3,\n",
       "       0, 1, 4, 3, 5, 2, 2, 3, 5, 3, 1, 1, 2, 0, 0, 5, 5, 5, 4, 2, 5, 5,\n",
       "       5, 1, 1, 0, 2, 2, 0, 2, 4, 2, 5, 2, 5, 2, 4, 1, 0, 0, 4, 0, 1, 1,\n",
       "       4, 5, 3, 5, 5, 4, 0, 2, 5, 1, 2, 0, 4, 0, 3, 0, 2, 0, 1, 1, 5, 2,\n",
       "       0, 2, 2, 1, 0, 1, 4, 5, 4, 4, 5, 1, 2, 3, 2, 1, 2, 2, 4, 5, 1, 4,\n",
       "       5, 3, 4, 3, 2, 5, 2, 0, 4, 5, 1, 0, 2, 5, 5, 2, 2, 2, 2, 4, 1, 2,\n",
       "       1, 0, 4, 0, 0, 2, 1, 3, 0, 2, 4, 4, 0, 5, 0, 1, 5, 0, 0, 0, 4, 2,\n",
       "       2, 5, 5, 3, 5, 2, 1, 1, 2, 2, 0, 3, 2, 0, 0, 5, 0, 5, 2, 1, 4, 1,\n",
       "       0, 1, 3, 5, 5, 0, 2, 4, 4, 1, 4, 1, 5, 0, 5, 2, 1, 0, 2, 0, 0, 0,\n",
       "       5, 1, 2, 1, 4, 5, 0, 5, 4, 4, 3, 4, 1, 4, 0, 4, 0, 2, 5, 3, 2, 3,\n",
       "       2, 5, 4, 2, 5, 4, 1, 5, 4, 3, 0, 2, 5, 4, 2, 1, 4, 2, 1, 1, 1, 0,\n",
       "       0, 1, 2, 2, 5, 4, 1, 5, 1, 4, 0, 5, 5, 0, 1, 3, 2, 3, 1, 0, 4, 3,\n",
       "       4, 5, 1, 3, 0, 5, 0, 4, 5, 0, 4, 2, 0, 0, 3, 2, 3, 3, 4, 1, 4, 5,\n",
       "       0, 5, 3, 4, 5, 1, 5, 5, 2, 4, 0, 3, 4, 3, 2, 3, 0, 1, 5, 5, 1, 0,\n",
       "       4, 2, 5, 4, 5, 1, 2, 5, 3, 1, 2, 3, 4, 1, 4, 3, 5, 3, 5, 4, 1, 1,\n",
       "       5, 5, 5, 5, 2, 0, 5, 2, 1, 2, 4, 4, 0, 4, 0, 3, 5, 5, 5, 2, 5, 0,\n",
       "       1, 5, 1, 2, 0, 0, 0, 1, 0, 4, 3, 2, 5, 4, 0, 4, 5, 5, 2, 1, 5, 5,\n",
       "       1, 2, 5, 4, 5, 5, 1, 0, 0, 4, 5, 2, 0, 0, 3, 1, 0, 4, 1, 0, 4, 4,\n",
       "       2, 5, 5, 4, 2, 4, 2, 3, 4, 2, 0, 0, 4, 5, 2, 1, 4, 4, 1, 4, 1, 5,\n",
       "       4, 0, 4, 2, 5, 4, 2, 1, 0, 5, 4, 5, 0, 4, 5, 2, 2, 4, 4, 2, 4, 5,\n",
       "       0, 4, 0, 5, 5, 4, 4, 5])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_lstm(optimizer='adam', learning_rate=0.0001):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), input_shape=(\n",
    "        padded_data_value.shape[1], padded_data_value.shape[2], 1)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('elu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(\n",
    "        (2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('elu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(\n",
    "        (2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(128, (2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('elu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(\n",
    "        (2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(128, (2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('elu'))\n",
    "\n",
    "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten()))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256)))\n",
    "    model.add(tf.keras.layers.Dense(6, activation=\"softmax\"))\n",
    "    optimiser = tf.keras.optimizers.get(optimizer)\n",
    "    optimiser.learning_rate.assign(learning_rate)\n",
    "    model.compile(optimizer=optimiser,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    # model.summary()\n",
    "    str_learning_rate = str(learning_rate).replace('.', '')\n",
    "    # csv_logger = tf.keras.callbacks.CSVLogger(\n",
    "    #     'robust_cnn_lstm{0}_{1}.csv'.format(optimizer, str_learning_rate))\n",
    "    history = model.fit(train_data_value, train_data_target, validation_data=(\n",
    "        test_data_value, test_data_target), batch_size=32, epochs=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 15s 121ms/step - loss: 1.6856 - accuracy: 0.2903 - val_loss: 1.7427 - val_accuracy: 0.2170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x12345bdfdc0>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"ravdess_train_data_value\", train_data_value)\n",
    "np.save(\"ravdess_train_data_target\", train_data_target)\n",
    "np.save(\"ravdess_test_data_value\", test_data_value)\n",
    "np.save(\"ravdess_test_data_target\", test_data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
