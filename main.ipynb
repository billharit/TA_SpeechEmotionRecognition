{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Saved Dataset\n",
    "train_data_value = np.load('saved_dataset/40_2048_512_train_data_value.npy')\n",
    "train_data_target = np.load('saved_dataset/40_2048_512_train_data_target.npy')\n",
    "test_data_value = np.load('saved_dataset/40_2048_512_test_data_value.npy')\n",
    "test_data_target = np.load('saved_dataset/40_2048_512_test_data_target.npy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration And Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIgnal\n",
    "explore_folder = os.listdir(\"./dataset/inspect/\")\n",
    "signal_list = {\"Name\": [], \"Signal\": []}\n",
    "for x in explore_folder:\n",
    "    signal, sample_rate = librosa.load(\"./dataset/inspect/{}\".format(x), sr=16000)\n",
    "    signal_list[\"Name\"].append(x)\n",
    "    signal_list[\"Signal\"].append(signal)\n",
    "\n",
    "# MfCC Constant\n",
    "SAMPLE_RATE = 16000\n",
    "n_mfcc = 40\n",
    "n_fft = 2048\n",
    "hop_length=512\n",
    "\n",
    "# MfCC\n",
    "mfcc_list = {\"Name\": [], \"Vector\": []}\n",
    "for x,y in zip(signal_list[\"Name\"],signal_list[\"Signal\"]):\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "    y=y, sr=SAMPLE_RATE, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    mfcc_list[\"Name\"].append(x)\n",
    "    mfcc_list[\"Vector\"].append(mfcc)    \n",
    "\n",
    "# MFCC Padded\n",
    "padded_mfcc_list = {\"Name\": [], \"Vector\": []}\n",
    "for x,y in zip(mfcc_list[\"Name\"],mfcc_list[\"Vector\"]):\n",
    "    padded_data = tf.keras.preprocessing.sequence.pad_sequences(y, maxlen=156, padding=\"post\")\n",
    "    padded_mfcc_list[\"Name\"].append(x)\n",
    "    padded_mfcc_list[\"Vector\"].append(padded_data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to Graph Function\n",
    "def plot_to_waveform(name, signal, type):\n",
    "    plt.figure(figsize=(4,2))\n",
    "    plt.title(name, size=8)\n",
    "    plt.xlabel('Time (s)', fontsize=8)\n",
    "    plt.xticks(fontsize=8)\n",
    "    plt.ylabel('Amplitude', fontsize=8)\n",
    "    plt.yticks(fontsize=8)\n",
    "    librosa.display.waveshow(signal,sr=SAMPLE_RATE,color='pink')\n",
    "    if type == \"save\":\n",
    "        plt.savefig(\"gambar_data/signal/{}.png\".format(name[:-4]))\n",
    "    else:\n",
    "        return plt.show()\n",
    "    \n",
    "def plot_to_mfcc(name, signal, type):\n",
    "    plt.figure(figsize=(4,2))\n",
    "    plt.title(name, size=8)\n",
    "    plt.xlabel('Frame', fontsize=8)\n",
    "    plt.xticks(fontsize=8)\n",
    "    plt.ylabel('MFCC', fontsize=8)\n",
    "    plt.yticks(fontsize=8)\n",
    "    librosa.display.specshow(signal,sr=SAMPLE_RATE, n_fft=n_fft, hop_length=hop_length )\n",
    "    plt.gca().set_ylabel('MFCC Coefficients', labelpad=10)\n",
    "    plt.gca().set_xlabel('Frame', labelpad=10)\n",
    "    plt.colorbar(format=\"%+2.f dB\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if type == \"save\":\n",
    "        plt.savefig(\"gambar_data/mfcc/{}.png\".format(name[:-4]))\n",
    "    elif type == \"save_padded\":\n",
    "        plt.savefig(\"gambar_data/mfcc_padded/{}.png\".format(name[:-4]))\n",
    "    else:\n",
    "        return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_to_mfcc(mfcc_list[\"Name\"][1], padded_data, \"show\")\n",
    "# for x,y in zip(signal_list[\"Name\"],signal_list[\"Signal\"]):\n",
    "#     plot_to_waveform(x, y)\n",
    "# for x,y in zip(mfcc_list[\"Name\"],mfcc_list[\"Vector\"]):\n",
    "#     plot_to_mfcc(x, y, \"save\")\n",
    "# for x,y in zip(padded_mfcc_list[\"Name\"],padded_mfcc_list[\"Vector\"]):\n",
    "#     plot_to_mfcc(x, y, \"save_padded\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_model_1():\n",
    "    model = tf.keras.Sequential()\n",
    "    base_model = tf.keras.applications.resnet_v2.ResNet50V2(\n",
    "        include_top=False, weights=None, input_shape=(train_data_value.shape[1], train_data_value.shape[2], 1))\n",
    "    model.add(base_model)\n",
    "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten()))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)))\n",
    "    # model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "    # model.add(tf.keras.layers.Dropout(0.3))\n",
    "    model.add(tf.keras.layers.Dense(6, activation=\"softmax\"))\n",
    "    optimiser = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimiser,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    csv_logger = tf.keras.callbacks.CSVLogger('resnet_unweighted.csv')\n",
    "    # history = model.fit(train_data_value, train_data_target, validation_data=(\n",
    "    #     test_data_value, test_data_target), batch_size=64, epochs=30, callbacks=[csv_logger])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 5, 2, 2048)        23558528  \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 5, 4096)          0         \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 256)              4326400   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 1542      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,886,470\n",
      "Trainable params: 27,841,030\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelasdqw = resnet_model_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_lstm_unweighted(optimizer='adam', learning_rate=0.0001):\n",
    "    model = tf.keras.Sequential()\n",
    "    base_model = tf.keras.applications.resnet_v2.ResNet50V2(\n",
    "        include_top=False, weights=None, input_shape=(train_data_value.shape[1], train_data_value.shape[2], 1))\n",
    "    model.add(base_model)\n",
    "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten()))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)))\n",
    "    model.add(tf.keras.layers.Dense(6, activation=\"softmax\"))\n",
    "    optimiser = tf.keras.optimizers.get(optimizer)\n",
    "    optimiser.learning_rate.assign(learning_rate)\n",
    "    model.compile(optimizer=optimiser,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    str_learning_rate = str(learning_rate).replace('.', '')\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=5)\n",
    "    csv_logger = tf.keras.callbacks.CSVLogger(\n",
    "        'resnet_lstm{0}_{1}.csv'.format(optimizer, str_learning_rate))\n",
    "    # model.summary()\n",
    "    base_model.summary()\n",
    "    # history = model.fit(train_data_value, train_data_target, validation_data=(\n",
    "    #     test_data_value, test_data_target), batch_size=32, epochs=90, callbacks=[csv_logger, early_stop])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 5, 2, 2048)        23558528  \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 5, 4096)          0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 256)              4326400   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 1542      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,886,470\n",
      "Trainable params: 27,841,030\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelasdqwz = resnet_lstm_unweighted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50v2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 156, 40, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 162, 46, 1)   0           ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 78, 20, 64)   3200        ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 80, 22, 64)   0           ['conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 39, 10, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_preact_bn (BatchN  (None, 39, 10, 64)  256         ['pool1_pool[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block1_preact_relu (Acti  (None, 39, 10, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 39, 10, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 39, 10, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 39, 10, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_pad (ZeroPaddin  (None, 41, 12, 64)  0           ['conv2_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 39, 10, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 39, 10, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 39, 10, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 39, 10, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 39, 10, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_out (Add)         (None, 39, 10, 256)  0           ['conv2_block1_0_conv[0][0]',    \n",
      "                                                                  'conv2_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_bn (BatchN  (None, 39, 10, 256)  1024       ['conv2_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_relu (Acti  (None, 39, 10, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 39, 10, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 39, 10, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 39, 10, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_pad (ZeroPaddin  (None, 41, 12, 64)  0           ['conv2_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 39, 10, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 39, 10, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 39, 10, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 39, 10, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_out (Add)         (None, 39, 10, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_bn (BatchN  (None, 39, 10, 256)  1024       ['conv2_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_relu (Acti  (None, 39, 10, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 39, 10, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 39, 10, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 39, 10, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_pad (ZeroPaddin  (None, 41, 12, 64)  0           ['conv2_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 20, 5, 64)    36864       ['conv2_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 20, 5, 64)   256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 20, 5, 64)   0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 20, 5, 256)  0           ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 20, 5, 256)   16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_out (Add)         (None, 20, 5, 256)   0           ['max_pooling2d_9[0][0]',        \n",
      "                                                                  'conv2_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_bn (BatchN  (None, 20, 5, 256)  1024        ['conv2_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_relu (Acti  (None, 20, 5, 256)  0           ['conv3_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 20, 5, 128)   32768       ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 20, 5, 128)  512         ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 20, 5, 128)  0           ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_pad (ZeroPaddin  (None, 22, 7, 128)  0           ['conv3_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 20, 5, 128)   147456      ['conv3_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 20, 5, 128)  512         ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 20, 5, 128)  0           ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 20, 5, 512)   131584      ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 20, 5, 512)   66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_out (Add)         (None, 20, 5, 512)   0           ['conv3_block1_0_conv[0][0]',    \n",
      "                                                                  'conv3_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_bn (BatchN  (None, 20, 5, 512)  2048        ['conv3_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_relu (Acti  (None, 20, 5, 512)  0           ['conv3_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 20, 5, 128)   65536       ['conv3_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 20, 5, 128)  512         ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 20, 5, 128)  0           ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_pad (ZeroPaddin  (None, 22, 7, 128)  0           ['conv3_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 20, 5, 128)   147456      ['conv3_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 20, 5, 128)  512         ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 20, 5, 128)  0           ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 20, 5, 512)   66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_out (Add)         (None, 20, 5, 512)   0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_bn (BatchN  (None, 20, 5, 512)  2048        ['conv3_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_relu (Acti  (None, 20, 5, 512)  0           ['conv3_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 20, 5, 128)   65536       ['conv3_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 20, 5, 128)  512         ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 20, 5, 128)  0           ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_pad (ZeroPaddin  (None, 22, 7, 128)  0           ['conv3_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 20, 5, 128)   147456      ['conv3_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 20, 5, 128)  512         ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 20, 5, 128)  0           ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 20, 5, 512)   66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_out (Add)         (None, 20, 5, 512)   0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_bn (BatchN  (None, 20, 5, 512)  2048        ['conv3_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_relu (Acti  (None, 20, 5, 512)  0           ['conv3_block4_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 20, 5, 128)   65536       ['conv3_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 20, 5, 128)  512         ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 20, 5, 128)  0           ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_pad (ZeroPaddin  (None, 22, 7, 128)  0           ['conv3_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 10, 3, 128)   147456      ['conv3_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 10, 3, 128)  512         ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 10, 3, 128)  0           ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 10, 3, 512)  0           ['conv3_block3_out[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 10, 3, 512)   66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_out (Add)         (None, 10, 3, 512)   0           ['max_pooling2d_10[0][0]',       \n",
      "                                                                  'conv3_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_bn (BatchN  (None, 10, 3, 512)  2048        ['conv3_block4_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_relu (Acti  (None, 10, 3, 512)  0           ['conv4_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 10, 3, 256)   131072      ['conv4_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 10, 3, 256)  1024        ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 10, 3, 256)  0           ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_pad (ZeroPaddin  (None, 12, 5, 256)  0           ['conv4_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 10, 3, 256)   589824      ['conv4_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 10, 3, 256)  1024        ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 10, 3, 256)  0           ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 10, 3, 1024)  525312      ['conv4_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 10, 3, 1024)  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_out (Add)         (None, 10, 3, 1024)  0           ['conv4_block1_0_conv[0][0]',    \n",
      "                                                                  'conv4_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_preact_bn (BatchN  (None, 10, 3, 1024)  4096       ['conv4_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block2_preact_relu (Acti  (None, 10, 3, 1024)  0          ['conv4_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 10, 3, 256)   262144      ['conv4_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 10, 3, 256)  1024        ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 10, 3, 256)  0           ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_pad (ZeroPaddin  (None, 12, 5, 256)  0           ['conv4_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 10, 3, 256)   589824      ['conv4_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 10, 3, 256)  1024        ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 10, 3, 256)  0           ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 10, 3, 1024)  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_out (Add)         (None, 10, 3, 1024)  0           ['conv4_block1_out[0][0]',       \n",
      "                                                                  'conv4_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_preact_bn (BatchN  (None, 10, 3, 1024)  4096       ['conv4_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block3_preact_relu (Acti  (None, 10, 3, 1024)  0          ['conv4_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 10, 3, 256)   262144      ['conv4_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 10, 3, 256)  1024        ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 10, 3, 256)  0           ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_pad (ZeroPaddin  (None, 12, 5, 256)  0           ['conv4_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 10, 3, 256)   589824      ['conv4_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 10, 3, 256)  1024        ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 10, 3, 256)  0           ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 10, 3, 1024)  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_out (Add)         (None, 10, 3, 1024)  0           ['conv4_block2_out[0][0]',       \n",
      "                                                                  'conv4_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_preact_bn (BatchN  (None, 10, 3, 1024)  4096       ['conv4_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block4_preact_relu (Acti  (None, 10, 3, 1024)  0          ['conv4_block4_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 10, 3, 256)   262144      ['conv4_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 10, 3, 256)  1024        ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 10, 3, 256)  0           ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_pad (ZeroPaddin  (None, 12, 5, 256)  0           ['conv4_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 10, 3, 256)   589824      ['conv4_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 10, 3, 256)  1024        ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 10, 3, 256)  0           ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 10, 3, 1024)  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_out (Add)         (None, 10, 3, 1024)  0           ['conv4_block3_out[0][0]',       \n",
      "                                                                  'conv4_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_preact_bn (BatchN  (None, 10, 3, 1024)  4096       ['conv4_block4_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block5_preact_relu (Acti  (None, 10, 3, 1024)  0          ['conv4_block5_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 10, 3, 256)   262144      ['conv4_block5_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 10, 3, 256)  1024        ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 10, 3, 256)  0           ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_pad (ZeroPaddin  (None, 12, 5, 256)  0           ['conv4_block5_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 10, 3, 256)   589824      ['conv4_block5_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 10, 3, 256)  1024        ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 10, 3, 256)  0           ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 10, 3, 1024)  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_out (Add)         (None, 10, 3, 1024)  0           ['conv4_block4_out[0][0]',       \n",
      "                                                                  'conv4_block5_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_preact_bn (BatchN  (None, 10, 3, 1024)  4096       ['conv4_block5_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block6_preact_relu (Acti  (None, 10, 3, 1024)  0          ['conv4_block6_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 10, 3, 256)   262144      ['conv4_block6_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 10, 3, 256)  1024        ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 10, 3, 256)  0           ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_pad (ZeroPaddin  (None, 12, 5, 256)  0           ['conv4_block6_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 5, 2, 256)    589824      ['conv4_block6_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 5, 2, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 5, 2, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 5, 2, 1024)  0           ['conv4_block5_out[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 5, 2, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_out (Add)         (None, 5, 2, 1024)   0           ['max_pooling2d_11[0][0]',       \n",
      "                                                                  'conv4_block6_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_bn (BatchN  (None, 5, 2, 1024)  4096        ['conv4_block6_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_relu (Acti  (None, 5, 2, 1024)  0           ['conv5_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 5, 2, 512)    524288      ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 5, 2, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 5, 2, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_pad (ZeroPaddin  (None, 7, 4, 512)   0           ['conv5_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 5, 2, 512)    2359296     ['conv5_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 5, 2, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 5, 2, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 5, 2, 2048)   2099200     ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 5, 2, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_out (Add)         (None, 5, 2, 2048)   0           ['conv5_block1_0_conv[0][0]',    \n",
      "                                                                  'conv5_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_bn (BatchN  (None, 5, 2, 2048)  8192        ['conv5_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_relu (Acti  (None, 5, 2, 2048)  0           ['conv5_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 5, 2, 512)    1048576     ['conv5_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 5, 2, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 5, 2, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_pad (ZeroPaddin  (None, 7, 4, 512)   0           ['conv5_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 5, 2, 512)    2359296     ['conv5_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 5, 2, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 5, 2, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 5, 2, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_out (Add)         (None, 5, 2, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_bn (BatchN  (None, 5, 2, 2048)  8192        ['conv5_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_relu (Acti  (None, 5, 2, 2048)  0           ['conv5_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 5, 2, 512)    1048576     ['conv5_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 5, 2, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 5, 2, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_pad (ZeroPaddin  (None, 7, 4, 512)   0           ['conv5_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 5, 2, 512)    2359296     ['conv5_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 5, 2, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 5, 2, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 5, 2, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_out (Add)         (None, 5, 2, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " post_bn (BatchNormalization)   (None, 5, 2, 2048)   8192        ['conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " post_relu (Activation)         (None, 5, 2, 2048)   0           ['post_bn[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,558,528\n",
      "Trainable params: 23,513,088\n",
      "Non-trainable params: 45,440\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelasdqwzz = resnet_lstm_unweighted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_model_weighted():\n",
    "    train_data_value_reshaped = np.zeros((train_data_value.shape[0], train_data_value.shape[1], train_data_value.shape[2], 3))\n",
    "    train_data_value_reshaped[..., 0] = train_data_value\n",
    "    train_data_value_reshaped[..., 1] = train_data_value\n",
    "    train_data_value_reshaped[..., 2] = train_data_value\n",
    "    test_data_value_reshaped = np.zeros((test_data_value.shape[0], test_data_value.shape[1], test_data_value.shape[2], 3))\n",
    "    test_data_value_reshaped[..., 0] = test_data_value\n",
    "    test_data_value_reshaped[..., 1] = test_data_value\n",
    "    test_data_value_reshaped[..., 2] = test_data_value\n",
    "    model = tf.keras.Sequential()\n",
    "    base_model = tf.keras.applications.resnet_v2.ResNet50V2(\n",
    "        include_top=False, weights=\"imagenet\", input_shape=(train_data_value_reshaped.shape[1], train_data_value_reshaped.shape[2], 3))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model.add(base_model)\n",
    "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten()))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)))\n",
    "    model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "    model.add(tf.keras.layers.Dense(6, activation=\"softmax\"))\n",
    "    optimiser = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimiser,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    csv_logger = tf.keras.callbacks.CSVLogger('resnet_weighted.csv')\n",
    "    history = model.fit(train_data_value_reshaped, train_data_target, validation_data=(\n",
    "        test_data_value_reshaped, test_data_target), batch_size=64, epochs=30, callbacks=[csv_logger])\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_model_weighted_trainable():\n",
    "    train_data_value_reshaped = np.zeros((train_data_value.shape[0], train_data_value.shape[1], train_data_value.shape[2], 3))\n",
    "    train_data_value_reshaped[..., 0] = train_data_value\n",
    "    train_data_value_reshaped[..., 1] = train_data_value\n",
    "    train_data_value_reshaped[..., 2] = train_data_value\n",
    "    test_data_value_reshaped = np.zeros((test_data_value.shape[0], test_data_value.shape[1], test_data_value.shape[2], 3))\n",
    "    test_data_value_reshaped[..., 0] = test_data_value\n",
    "    test_data_value_reshaped[..., 1] = test_data_value\n",
    "    test_data_value_reshaped[..., 2] = test_data_value\n",
    "    model = tf.keras.Sequential()\n",
    "    base_model = tf.keras.applications.resnet_v2.ResNet50V2(\n",
    "        include_top=False, weights=\"imagenet\", input_shape=(train_data_value_reshaped.shape[1], train_data_value_reshaped.shape[2], 3))\n",
    "    model.add(base_model)\n",
    "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten()))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)))\n",
    "    model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "    model.add(tf.keras.layers.Dense(6, activation=\"softmax\"))\n",
    "    optimiser = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimiser,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    csv_logger = tf.keras.callbacks.CSVLogger('resnet_weighted_trainable.csv')\n",
    "    history = model.fit(train_data_value_reshaped, train_data_target, validation_data=(\n",
    "        test_data_value_reshaped, test_data_target), batch_size=64, epochs=30, callbacks=[csv_logger])\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94668760/94668760 [==============================] - 27s 0us/step\n",
      "Epoch 1/30\n",
      "94/94 [==============================] - 18s 113ms/step - loss: 1.7493 - accuracy: 0.2498 - val_loss: 1.7700 - val_accuracy: 0.2317\n",
      "Epoch 2/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.7463 - accuracy: 0.2476 - val_loss: 1.7292 - val_accuracy: 0.2565\n",
      "Epoch 3/30\n",
      "94/94 [==============================] - 8s 87ms/step - loss: 1.7161 - accuracy: 0.2699 - val_loss: 1.7046 - val_accuracy: 0.2760\n",
      "Epoch 4/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.7039 - accuracy: 0.2738 - val_loss: 1.6669 - val_accuracy: 0.2989\n",
      "Epoch 5/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6888 - accuracy: 0.2728 - val_loss: 1.6564 - val_accuracy: 0.3015\n",
      "Epoch 6/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6658 - accuracy: 0.3004 - val_loss: 1.6605 - val_accuracy: 0.2968\n",
      "Epoch 7/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6637 - accuracy: 0.2992 - val_loss: 1.6549 - val_accuracy: 0.2968\n",
      "Epoch 8/30\n",
      "94/94 [==============================] - 8s 87ms/step - loss: 1.6841 - accuracy: 0.2878 - val_loss: 1.6597 - val_accuracy: 0.2908\n",
      "Epoch 9/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6634 - accuracy: 0.2928 - val_loss: 1.6713 - val_accuracy: 0.2928\n",
      "Epoch 10/30\n",
      "94/94 [==============================] - 8s 87ms/step - loss: 1.6588 - accuracy: 0.3039 - val_loss: 1.6401 - val_accuracy: 0.3237\n",
      "Epoch 11/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6516 - accuracy: 0.3046 - val_loss: 1.6529 - val_accuracy: 0.2760\n",
      "Epoch 12/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6479 - accuracy: 0.3002 - val_loss: 1.6522 - val_accuracy: 0.2962\n",
      "Epoch 13/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6389 - accuracy: 0.3135 - val_loss: 1.6498 - val_accuracy: 0.2948\n",
      "Epoch 14/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6410 - accuracy: 0.3109 - val_loss: 1.6391 - val_accuracy: 0.3304\n",
      "Epoch 15/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6320 - accuracy: 0.3151 - val_loss: 1.6432 - val_accuracy: 0.3183\n",
      "Epoch 16/30\n",
      "94/94 [==============================] - 8s 85ms/step - loss: 1.6386 - accuracy: 0.3136 - val_loss: 1.6665 - val_accuracy: 0.2935\n",
      "Epoch 17/30\n",
      "94/94 [==============================] - 8s 85ms/step - loss: 1.6207 - accuracy: 0.3160 - val_loss: 1.6464 - val_accuracy: 0.2827\n",
      "Epoch 18/30\n",
      "94/94 [==============================] - 8s 85ms/step - loss: 1.6279 - accuracy: 0.3158 - val_loss: 1.6559 - val_accuracy: 0.3170\n",
      "Epoch 19/30\n",
      "94/94 [==============================] - 8s 85ms/step - loss: 1.6156 - accuracy: 0.3219 - val_loss: 1.6211 - val_accuracy: 0.3177\n",
      "Epoch 20/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6459 - accuracy: 0.3086 - val_loss: 1.6388 - val_accuracy: 0.3230\n",
      "Epoch 21/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6172 - accuracy: 0.3210 - val_loss: 1.6149 - val_accuracy: 0.3257\n",
      "Epoch 22/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6176 - accuracy: 0.3193 - val_loss: 1.6555 - val_accuracy: 0.2989\n",
      "Epoch 23/30\n",
      "94/94 [==============================] - 8s 85ms/step - loss: 1.6281 - accuracy: 0.3193 - val_loss: 1.6381 - val_accuracy: 0.3116\n",
      "Epoch 24/30\n",
      "94/94 [==============================] - 8s 85ms/step - loss: 1.6065 - accuracy: 0.3286 - val_loss: 1.6444 - val_accuracy: 0.3163\n",
      "Epoch 25/30\n",
      "94/94 [==============================] - 8s 85ms/step - loss: 1.6031 - accuracy: 0.3261 - val_loss: 1.6194 - val_accuracy: 0.3123\n",
      "Epoch 26/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6056 - accuracy: 0.3289 - val_loss: 1.6359 - val_accuracy: 0.3251\n",
      "Epoch 27/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6138 - accuracy: 0.3237 - val_loss: 1.7063 - val_accuracy: 0.2948\n",
      "Epoch 28/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.7128 - accuracy: 0.2716 - val_loss: 1.6941 - val_accuracy: 0.2760\n",
      "Epoch 29/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6661 - accuracy: 0.2945 - val_loss: 1.6687 - val_accuracy: 0.2942\n",
      "Epoch 30/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6420 - accuracy: 0.3151 - val_loss: 1.6614 - val_accuracy: 0.2928\n"
     ]
    }
   ],
   "source": [
    "resnet_model_weighted, resnet_weighted_history = resnet_model_weighted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "94/94 [==============================] - 37s 263ms/step - loss: 1.4502 - accuracy: 0.4090 - val_loss: 2.0030 - val_accuracy: 0.3304\n",
      "Epoch 2/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 1.3239 - accuracy: 0.4732 - val_loss: 2.4130 - val_accuracy: 0.2807\n",
      "Epoch 3/30\n",
      "94/94 [==============================] - 21s 222ms/step - loss: 1.2393 - accuracy: 0.5110 - val_loss: 2.5449 - val_accuracy: 0.3264\n",
      "Epoch 4/30\n",
      "94/94 [==============================] - 21s 222ms/step - loss: 1.1645 - accuracy: 0.5548 - val_loss: 2.3452 - val_accuracy: 0.3237\n",
      "Epoch 5/30\n",
      "94/94 [==============================] - 20s 217ms/step - loss: 1.1332 - accuracy: 0.5631 - val_loss: 2.5571 - val_accuracy: 0.2942\n",
      "Epoch 6/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 1.0692 - accuracy: 0.5935 - val_loss: 1.8947 - val_accuracy: 0.3660\n",
      "Epoch 7/30\n",
      "94/94 [==============================] - 21s 223ms/step - loss: 1.0230 - accuracy: 0.6135 - val_loss: 1.6168 - val_accuracy: 0.4768\n",
      "Epoch 8/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 1.0034 - accuracy: 0.6237 - val_loss: 2.9262 - val_accuracy: 0.2747\n",
      "Epoch 9/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 1.0382 - accuracy: 0.6089 - val_loss: 1.6370 - val_accuracy: 0.4298\n",
      "Epoch 10/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 0.9752 - accuracy: 0.6353 - val_loss: 2.8811 - val_accuracy: 0.2767\n",
      "Epoch 11/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 0.8678 - accuracy: 0.6876 - val_loss: 1.7977 - val_accuracy: 0.4480\n",
      "Epoch 12/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 0.8316 - accuracy: 0.6906 - val_loss: 1.3334 - val_accuracy: 0.5245\n",
      "Epoch 13/30\n",
      "94/94 [==============================] - 21s 222ms/step - loss: 0.7443 - accuracy: 0.7259 - val_loss: 1.6217 - val_accuracy: 0.4600\n",
      "Epoch 14/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 0.6874 - accuracy: 0.7552 - val_loss: 1.3522 - val_accuracy: 0.5453\n",
      "Epoch 15/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 0.6341 - accuracy: 0.7712 - val_loss: 1.5342 - val_accuracy: 0.5017\n",
      "Epoch 16/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 0.5624 - accuracy: 0.7994 - val_loss: 2.0656 - val_accuracy: 0.4466\n",
      "Epoch 17/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 0.5230 - accuracy: 0.8140 - val_loss: 2.1100 - val_accuracy: 0.4600\n",
      "Epoch 18/30\n",
      "94/94 [==============================] - 21s 222ms/step - loss: 0.6306 - accuracy: 0.7675 - val_loss: 1.8267 - val_accuracy: 0.4943\n",
      "Epoch 19/30\n",
      "94/94 [==============================] - 21s 223ms/step - loss: 0.5728 - accuracy: 0.7914 - val_loss: 1.5476 - val_accuracy: 0.5581\n",
      "Epoch 20/30\n",
      "94/94 [==============================] - 21s 227ms/step - loss: 0.4094 - accuracy: 0.8539 - val_loss: 1.6255 - val_accuracy: 0.5373\n",
      "Epoch 21/30\n",
      "94/94 [==============================] - 21s 224ms/step - loss: 0.3334 - accuracy: 0.8859 - val_loss: 1.5598 - val_accuracy: 0.5594\n",
      "Epoch 22/30\n",
      "94/94 [==============================] - 21s 222ms/step - loss: 0.3405 - accuracy: 0.8873 - val_loss: 1.5846 - val_accuracy: 0.5520\n",
      "Epoch 23/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 0.2904 - accuracy: 0.9002 - val_loss: 1.9632 - val_accuracy: 0.5218\n",
      "Epoch 24/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 0.2683 - accuracy: 0.9091 - val_loss: 1.8678 - val_accuracy: 0.5299\n",
      "Epoch 25/30\n",
      "94/94 [==============================] - 21s 222ms/step - loss: 0.2489 - accuracy: 0.9145 - val_loss: 1.6947 - val_accuracy: 0.5581\n",
      "Epoch 26/30\n",
      "94/94 [==============================] - 21s 223ms/step - loss: 0.2061 - accuracy: 0.9313 - val_loss: 2.2835 - val_accuracy: 0.5178\n",
      "Epoch 27/30\n",
      "94/94 [==============================] - 21s 223ms/step - loss: 0.2135 - accuracy: 0.9263 - val_loss: 2.1661 - val_accuracy: 0.5413\n",
      "Epoch 28/30\n",
      "94/94 [==============================] - 21s 223ms/step - loss: 0.1918 - accuracy: 0.9340 - val_loss: 1.8123 - val_accuracy: 0.5601\n",
      "Epoch 29/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 0.1669 - accuracy: 0.9449 - val_loss: 2.1418 - val_accuracy: 0.5561\n",
      "Epoch 30/30\n",
      "94/94 [==============================] - 21s 223ms/step - loss: 0.1644 - accuracy: 0.9457 - val_loss: 2.0548 - val_accuracy: 0.5588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 57). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet_model_trainable_weight\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet_model_trainable_weight\\assets\n"
     ]
    }
   ],
   "source": [
    "resnet_model_weighted_trainable, resnet_weighted_trainable_history = resnet_model_weighted_trainable()\n",
    "resnet_model_weighted_trainable.save(\"resnet_model_trainable_weight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "94/94 [==============================] - 32s 252ms/step - loss: 1.5680 - accuracy: 0.3430 - val_loss: 3.0238 - val_accuracy: 0.1706\n",
      "Epoch 2/30\n",
      "94/94 [==============================] - 21s 225ms/step - loss: 1.4434 - accuracy: 0.4070 - val_loss: 3.1265 - val_accuracy: 0.1706\n",
      "Epoch 3/30\n",
      "94/94 [==============================] - 21s 222ms/step - loss: 1.3606 - accuracy: 0.4572 - val_loss: 3.7027 - val_accuracy: 0.1706\n",
      "Epoch 4/30\n",
      "94/94 [==============================] - 21s 224ms/step - loss: 1.3887 - accuracy: 0.4393 - val_loss: 2.7338 - val_accuracy: 0.2445\n",
      "Epoch 5/30\n",
      "94/94 [==============================] - 21s 223ms/step - loss: 1.3273 - accuracy: 0.4720 - val_loss: 2.4987 - val_accuracy: 0.3674\n",
      "Epoch 6/30\n",
      "94/94 [==============================] - 21s 225ms/step - loss: 1.2750 - accuracy: 0.5004 - val_loss: 1.5170 - val_accuracy: 0.3714\n",
      "Epoch 7/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 1.3947 - accuracy: 0.4368 - val_loss: 1.9422 - val_accuracy: 0.3150\n",
      "Epoch 8/30\n",
      "94/94 [==============================] - 21s 219ms/step - loss: 1.2916 - accuracy: 0.4883 - val_loss: 2.6914 - val_accuracy: 0.2048\n",
      "Epoch 9/30\n",
      "94/94 [==============================] - 21s 219ms/step - loss: 1.3437 - accuracy: 0.4567 - val_loss: 2.7050 - val_accuracy: 0.1786\n",
      "Epoch 10/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 1.2716 - accuracy: 0.4979 - val_loss: 2.1390 - val_accuracy: 0.2807\n",
      "Epoch 11/30\n",
      "94/94 [==============================] - 21s 219ms/step - loss: 1.2003 - accuracy: 0.5234 - val_loss: 1.4502 - val_accuracy: 0.4426\n",
      "Epoch 12/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 1.1830 - accuracy: 0.5317 - val_loss: 1.4247 - val_accuracy: 0.4500\n",
      "Epoch 13/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 1.2358 - accuracy: 0.5150 - val_loss: 1.3557 - val_accuracy: 0.4493\n",
      "Epoch 14/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 1.1609 - accuracy: 0.5414 - val_loss: 1.7824 - val_accuracy: 0.3284\n",
      "Epoch 15/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 1.1423 - accuracy: 0.5506 - val_loss: 1.5204 - val_accuracy: 0.4090\n",
      "Epoch 16/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 1.1553 - accuracy: 0.5456 - val_loss: 1.3067 - val_accuracy: 0.5158\n",
      "Epoch 17/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 1.1047 - accuracy: 0.5688 - val_loss: 1.7285 - val_accuracy: 0.3358\n",
      "Epoch 18/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 1.1093 - accuracy: 0.5644 - val_loss: 1.9176 - val_accuracy: 0.3909\n",
      "Epoch 19/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 1.1047 - accuracy: 0.5636 - val_loss: 1.9505 - val_accuracy: 0.4063\n",
      "Epoch 20/30\n",
      "94/94 [==============================] - 21s 219ms/step - loss: 1.0685 - accuracy: 0.5869 - val_loss: 1.5647 - val_accuracy: 0.4459\n",
      "Epoch 21/30\n",
      "94/94 [==============================] - 21s 219ms/step - loss: 1.0680 - accuracy: 0.5940 - val_loss: 1.9083 - val_accuracy: 0.3318\n",
      "Epoch 22/30\n",
      "94/94 [==============================] - 21s 219ms/step - loss: 1.1105 - accuracy: 0.5654 - val_loss: 1.5782 - val_accuracy: 0.4365\n",
      "Epoch 23/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 1.2491 - accuracy: 0.5098 - val_loss: 1.4268 - val_accuracy: 0.4547\n",
      "Epoch 24/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 1.2008 - accuracy: 0.5278 - val_loss: 1.3050 - val_accuracy: 0.4849\n",
      "Epoch 25/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 1.1164 - accuracy: 0.5681 - val_loss: 1.3483 - val_accuracy: 0.4876\n",
      "Epoch 26/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 1.0765 - accuracy: 0.5770 - val_loss: 1.1545 - val_accuracy: 0.5467\n",
      "Epoch 27/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 1.0377 - accuracy: 0.5985 - val_loss: 1.3472 - val_accuracy: 0.5212\n",
      "Epoch 28/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 1.0033 - accuracy: 0.6148 - val_loss: 1.2651 - val_accuracy: 0.5252\n",
      "Epoch 29/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 1.0106 - accuracy: 0.6115 - val_loss: 1.4671 - val_accuracy: 0.4560\n",
      "Epoch 30/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 1.0848 - accuracy: 0.5794 - val_loss: 1.2826 - val_accuracy: 0.5285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 57). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet_model_unweighted\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet_model_unweighted\\assets\n"
     ]
    }
   ],
   "source": [
    "resnet_model_unweighted, resnet_unweighted_history = resnet_model_1()\n",
    "resnet_model_unweighted.save(\"resnet_model_unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 57). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet_model_weighted\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet_model_weighted\\assets\n"
     ]
    }
   ],
   "source": [
    "resnet_model_weighted.save(\"resnet_model_weighted\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_lstm():\n",
    "    model = tf.keras.Sequential()\n",
    "    # base_model = tf.keras.applications.resnet_v2.ResNet50V2(\n",
    "    #     include_top=False, weights=None, input_shape=(train_data_value.shape[1], train_data_value.shape[2], 1))\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), input_shape=(\n",
    "    train_data_value.shape[1], train_data_value.shape[2], 3)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('elu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('elu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(128, (2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('elu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(128, (2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('elu'))\n",
    "\n",
    "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten()))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)))\n",
    "    model.add(tf.keras.layers.Dense(6, activation=\"softmax\"))\n",
    "    optimiser = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimiser,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    # csv_logger = tf.keras.callbacks.CSVLogger('robust_rmsprop.csv')\n",
    "    # history = model.fit(train_data_value, train_data_target, validation_data=(\n",
    "    #     test_data_value, test_data_target), batch_size=32, epochs=30, callbacks=[csv_logger])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_54 (Conv2D)          (None, 154, 38, 64)       640       \n",
      "                                                                 \n",
      " batch_normalization_48 (Bat  (None, 154, 38, 64)      256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_48 (Activation)  (None, 154, 38, 64)       0         \n",
      "                                                                 \n",
      " max_pooling2d_37 (MaxPoolin  (None, 77, 19, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 75, 17, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_49 (Bat  (None, 75, 17, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_49 (Activation)  (None, 75, 17, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_38 (MaxPoolin  (None, 38, 9, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_56 (Conv2D)          (None, 37, 8, 128)        32896     \n",
      "                                                                 \n",
      " batch_normalization_50 (Bat  (None, 37, 8, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_50 (Activation)  (None, 37, 8, 128)        0         \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPoolin  (None, 19, 4, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_57 (Conv2D)          (None, 18, 3, 128)        65664     \n",
      "                                                                 \n",
      " batch_normalization_51 (Bat  (None, 18, 3, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_51 (Activation)  (None, 18, 3, 128)        0         \n",
      "                                                                 \n",
      " time_distributed_13 (TimeDi  (None, 18, 384)          0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " bidirectional_13 (Bidirecti  (None, 256)              525312    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 6)                 1542      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 664,518\n",
      "Trainable params: 663,750\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "187/187 [==============================] - 13s 46ms/step - loss: 1.5063 - accuracy: 0.3862 - val_loss: 1.8474 - val_accuracy: 0.2559\n",
      "Epoch 2/30\n",
      "187/187 [==============================] - 8s 41ms/step - loss: 1.2561 - accuracy: 0.5063 - val_loss: 1.3252 - val_accuracy: 0.4681\n",
      "Epoch 3/30\n",
      "187/187 [==============================] - 8s 42ms/step - loss: 1.1416 - accuracy: 0.5606 - val_loss: 1.8297 - val_accuracy: 0.3573\n",
      "Epoch 4/30\n",
      "187/187 [==============================] - 8s 42ms/step - loss: 1.0470 - accuracy: 0.5965 - val_loss: 2.2609 - val_accuracy: 0.3392\n",
      "Epoch 5/30\n",
      "187/187 [==============================] - 8s 41ms/step - loss: 0.9430 - accuracy: 0.6400 - val_loss: 3.0720 - val_accuracy: 0.2572\n",
      "Epoch 6/30\n",
      "187/187 [==============================] - 8s 42ms/step - loss: 0.8640 - accuracy: 0.6736 - val_loss: 1.4830 - val_accuracy: 0.4768\n",
      "Epoch 7/30\n",
      "187/187 [==============================] - 8s 42ms/step - loss: 0.7660 - accuracy: 0.7092 - val_loss: 2.3364 - val_accuracy: 0.3640\n",
      "Epoch 8/30\n",
      "187/187 [==============================] - 8s 42ms/step - loss: 0.6791 - accuracy: 0.7537 - val_loss: 4.4554 - val_accuracy: 0.1840\n",
      "Epoch 9/30\n",
      "187/187 [==============================] - 8s 42ms/step - loss: 0.5740 - accuracy: 0.7904 - val_loss: 2.8893 - val_accuracy: 0.3062\n",
      "Epoch 10/30\n",
      "187/187 [==============================] - 8s 41ms/step - loss: 0.4731 - accuracy: 0.8322 - val_loss: 1.2562 - val_accuracy: 0.5977\n",
      "Epoch 11/30\n",
      "187/187 [==============================] - 8s 42ms/step - loss: 0.3796 - accuracy: 0.8696 - val_loss: 1.6119 - val_accuracy: 0.5151\n",
      "Epoch 12/30\n",
      "187/187 [==============================] - 8s 42ms/step - loss: 0.2994 - accuracy: 0.9004 - val_loss: 4.4584 - val_accuracy: 0.2384\n",
      "Epoch 13/30\n",
      "187/187 [==============================] - 8s 44ms/step - loss: 0.2358 - accuracy: 0.9200 - val_loss: 1.6401 - val_accuracy: 0.5655\n",
      "Epoch 14/30\n",
      "187/187 [==============================] - 8s 42ms/step - loss: 0.1887 - accuracy: 0.9377 - val_loss: 1.7944 - val_accuracy: 0.5487\n",
      "Epoch 15/30\n",
      "187/187 [==============================] - 8s 41ms/step - loss: 0.1409 - accuracy: 0.9587 - val_loss: 1.8883 - val_accuracy: 0.5453\n",
      "Epoch 16/30\n",
      "187/187 [==============================] - 8s 41ms/step - loss: 0.1135 - accuracy: 0.9659 - val_loss: 2.7315 - val_accuracy: 0.4379\n",
      "Epoch 17/30\n",
      "187/187 [==============================] - 8s 40ms/step - loss: 0.0992 - accuracy: 0.9688 - val_loss: 3.8349 - val_accuracy: 0.3519\n",
      "Epoch 18/30\n",
      "187/187 [==============================] - 7s 40ms/step - loss: 0.0848 - accuracy: 0.9745 - val_loss: 2.0576 - val_accuracy: 0.5588\n",
      "Epoch 19/30\n",
      "187/187 [==============================] - 8s 40ms/step - loss: 0.0754 - accuracy: 0.9782 - val_loss: 1.6157 - val_accuracy: 0.6058\n",
      "Epoch 20/30\n",
      "187/187 [==============================] - 8s 41ms/step - loss: 0.0842 - accuracy: 0.9735 - val_loss: 1.7884 - val_accuracy: 0.5836\n",
      "Epoch 21/30\n",
      "187/187 [==============================] - 8s 41ms/step - loss: 0.0689 - accuracy: 0.9798 - val_loss: 2.3236 - val_accuracy: 0.5205\n",
      "Epoch 22/30\n",
      "187/187 [==============================] - 8s 40ms/step - loss: 0.0553 - accuracy: 0.9842 - val_loss: 2.1072 - val_accuracy: 0.5198\n",
      "Epoch 23/30\n",
      "187/187 [==============================] - 8s 41ms/step - loss: 0.0570 - accuracy: 0.9832 - val_loss: 3.8802 - val_accuracy: 0.3969\n",
      "Epoch 24/30\n",
      "187/187 [==============================] - 8s 40ms/step - loss: 0.0560 - accuracy: 0.9835 - val_loss: 2.8711 - val_accuracy: 0.5259\n",
      "Epoch 25/30\n",
      "187/187 [==============================] - 8s 40ms/step - loss: 0.0465 - accuracy: 0.9850 - val_loss: 3.8146 - val_accuracy: 0.4621\n",
      "Epoch 26/30\n",
      "187/187 [==============================] - 7s 40ms/step - loss: 0.0430 - accuracy: 0.9859 - val_loss: 2.2400 - val_accuracy: 0.5977\n",
      "Epoch 27/30\n",
      "187/187 [==============================] - 8s 41ms/step - loss: 0.0562 - accuracy: 0.9822 - val_loss: 3.2429 - val_accuracy: 0.4856\n",
      "Epoch 28/30\n",
      "187/187 [==============================] - 8s 41ms/step - loss: 0.0390 - accuracy: 0.9884 - val_loss: 2.3357 - val_accuracy: 0.5789\n",
      "Epoch 29/30\n",
      "187/187 [==============================] - 8s 40ms/step - loss: 0.0378 - accuracy: 0.9892 - val_loss: 2.1384 - val_accuracy: 0.6017\n",
      "Epoch 30/30\n",
      "187/187 [==============================] - 8s 40ms/step - loss: 0.0363 - accuracy: 0.9898 - val_loss: 2.5643 - val_accuracy: 0.5789\n"
     ]
    }
   ],
   "source": [
    "newmodel = cnn_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_46 (Conv2D)          (None, 154, 38, 64)       640       \n",
      "                                                                 \n",
      " batch_normalization_40 (Bat  (None, 154, 38, 64)      256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_40 (Activation)  (None, 154, 38, 64)       0         \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 77, 19, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 75, 17, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_41 (Bat  (None, 75, 17, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_41 (Activation)  (None, 75, 17, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 38, 9, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 37, 8, 128)        32896     \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 37, 8, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_42 (Activation)  (None, 37, 8, 128)        0         \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 19, 4, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 18, 3, 128)        65664     \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 18, 3, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_43 (Activation)  (None, 18, 3, 128)        0         \n",
      "                                                                 \n",
      " time_distributed_11 (TimeDi  (None, 18, 384)          0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " bidirectional_11 (Bidirecti  (None, 512)              1312768   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 6)                 3078      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,453,510\n",
      "Trainable params: 1,452,742\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "newmodel = cnn_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 154, 38, 64)       1792      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 154, 38, 64)       0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 77, 19, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 75, 17, 64)        36928     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 75, 17, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 38, 9, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 37, 8, 128)        32896     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 37, 8, 128)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 19, 4, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 18, 3, 128)        65664     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 18, 3, 128)       512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 18, 3, 128)        0         \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 18, 384)          0         \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 256)              525312    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 1542      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 664,646\n",
      "Trainable params: 664,390\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "newmodexxl = cnn_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robust_cnn_lstmadam002.csv\n"
     ]
    }
   ],
   "source": [
    "xx = 'adam'\n",
    "yy = 0.02\n",
    "str_learning_rate = str(yy).replace('.','')\n",
    "print('robust_cnn_lstm{}{}.csv'.format(xx, str_learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_32 (Conv2D)          (None, 154, 38, 64)       640       \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 154, 38, 64)      256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_32 (Activation)  (None, 154, 38, 64)       0         \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 77, 19, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 75, 17, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 75, 17, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_33 (Activation)  (None, 75, 17, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 38, 9, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 37, 8, 128)        32896     \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 37, 8, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_34 (Activation)  (None, 37, 8, 128)        0         \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 19, 4, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 18, 3, 128)        65664     \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 18, 3, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_35 (Activation)  (None, 18, 3, 128)        0         \n",
      "                                                                 \n",
      " time_distributed_7 (TimeDis  (None, 18, 384)          0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 128)               262656    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 401,094\n",
      "Trainable params: 400,326\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def cnn_lstmx():\n",
    "    model = tf.keras.Sequential()\n",
    "    # base_model = tf.keras.applications.resnet_v2.ResNet50V2(\n",
    "    #     include_top=False, weights=None, input_shape=(train_data_value.shape[1], train_data_value.shape[2], 1))\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), input_shape=(\n",
    "    train_data_value.shape[1], train_data_value.shape[2], 1)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('elu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('elu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(128, (2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('elu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(128, (2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('elu'))\n",
    "\n",
    "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten()))\n",
    "    model.add(tf.keras.layers.LSTM(128))\n",
    "    model.add(tf.keras.layers.Dense(6, activation=\"softmax\"))\n",
    "    optimiser = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimiser,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    # csv_logger = tf.keras.callbacks.CSVLogger('resnet_unweighted.csv')\n",
    "    # history = model.fit(train_data_value, train_data_target, validation_data=(\n",
    "    #     test_data_value, test_data_target), batch_size=32, epochs=60, callbacks=[csv_logger])\n",
    "    return model\n",
    "xxxxx = cnn_lstmx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adam\n",
      "adam\n",
      "x\n",
      "x\n",
      "a\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "optimizer_list = ['adam','x','a']\n",
    "learning_rate_list = [0.001, 0.01]\n",
    "\n",
    "for x in list(optimizer_list):\n",
    "    for y in learning_rate_list:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnnx():\n",
    "    model = tf.keras.Sequential()\n",
    "    # base_model = tf.keras.applications.resnet_v2.ResNet50V2(\n",
    "    #     include_top=False, weights=None, input_shape=(train_data_value.shape[1], train_data_value.shape[2], 1))\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), input_shape=(\n",
    "    train_data_value.shape[1], train_data_value.shape[2], 3)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('elu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('elu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(128, (2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('elu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(128, (2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation('elu'))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(6, activation=\"softmax\"))\n",
    "    optimiser = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimiser,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    # csv_logger = tf.keras.callbacks.CSVLogger('robust_rmsprop.csv')\n",
    "    # history = model.fit(train_data_value, train_data_target, validation_data=(\n",
    "    #     test_data_value, test_data_target), batch_size=32, epochs=30, callbacks=[csv_logger])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 154, 38, 64)       1792      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 154, 38, 64)      256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 154, 38, 64)       0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 77, 19, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 75, 17, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 75, 17, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 75, 17, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 38, 9, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 37, 8, 128)        32896     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 37, 8, 128)       512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 37, 8, 128)        0         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 19, 4, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 18, 3, 128)        65664     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 18, 3, 128)       512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 18, 3, 128)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6912)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 41478     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 180,294\n",
      "Trainable params: 179,526\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelcnn = cnnx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
