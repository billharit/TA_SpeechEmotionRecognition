{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Saved Dataset\n",
    "train_data_value = np.load('saved_dataset/40_2048_512_train_data_value.npy')\n",
    "train_data_target = np.load('saved_dataset/40_2048_512_train_data_target.npy')\n",
    "test_data_value = np.load('saved_dataset/40_2048_512_test_data_value.npy')\n",
    "test_data_target = np.load('saved_dataset/40_2048_512_test_data_target.npy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration And Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIgnal\n",
    "explore_folder = os.listdir(\"./dataset/inspect/\")\n",
    "signal_list = {\"Name\": [], \"Signal\": []}\n",
    "for x in explore_folder:\n",
    "    signal, sample_rate = librosa.load(\"./dataset/inspect/{}\".format(x), sr=16000)\n",
    "    signal_list[\"Name\"].append(x)\n",
    "    signal_list[\"Signal\"].append(signal)\n",
    "\n",
    "# MfCC Constant\n",
    "SAMPLE_RATE = 16000\n",
    "n_mfcc = 40\n",
    "n_fft = 2048\n",
    "hop_length=512\n",
    "\n",
    "# MfCC\n",
    "mfcc_list = {\"Name\": [], \"Vector\": []}\n",
    "for x,y in zip(signal_list[\"Name\"],signal_list[\"Signal\"]):\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "    y=y, sr=SAMPLE_RATE, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    mfcc_list[\"Name\"].append(x)\n",
    "    mfcc_list[\"Vector\"].append(mfcc)    \n",
    "\n",
    "# MFCC Padded\n",
    "padded_mfcc_list = {\"Name\": [], \"Vector\": []}\n",
    "for x,y in zip(mfcc_list[\"Name\"],mfcc_list[\"Vector\"]):\n",
    "    padded_data = tf.keras.preprocessing.sequence.pad_sequences(y, maxlen=156, padding=\"post\")\n",
    "    padded_mfcc_list[\"Name\"].append(x)\n",
    "    padded_mfcc_list[\"Vector\"].append(padded_data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to Graph Function\n",
    "def plot_to_waveform(name, signal, type):\n",
    "    plt.figure(figsize=(4,2))\n",
    "    plt.title(name, size=8)\n",
    "    plt.xlabel('Time (s)', fontsize=8)\n",
    "    plt.xticks(fontsize=8)\n",
    "    plt.ylabel('Amplitude', fontsize=8)\n",
    "    plt.yticks(fontsize=8)\n",
    "    librosa.display.waveshow(signal,sr=SAMPLE_RATE,color='pink')\n",
    "    if type == \"save\":\n",
    "        plt.savefig(\"gambar_data/signal/{}.png\".format(name[:-4]))\n",
    "    else:\n",
    "        return plt.show()\n",
    "    \n",
    "def plot_to_mfcc(name, signal, type):\n",
    "    plt.figure(figsize=(4,2))\n",
    "    plt.title(name, size=8)\n",
    "    plt.xlabel('Frame', fontsize=8)\n",
    "    plt.xticks(fontsize=8)\n",
    "    plt.ylabel('MFCC', fontsize=8)\n",
    "    plt.yticks(fontsize=8)\n",
    "    librosa.display.specshow(signal,sr=SAMPLE_RATE, n_fft=n_fft, hop_length=hop_length )\n",
    "    plt.gca().set_ylabel('MFCC Coefficients', labelpad=10)\n",
    "    plt.gca().set_xlabel('Frame', labelpad=10)\n",
    "    plt.colorbar(format=\"%+2.f dB\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if type == \"save\":\n",
    "        plt.savefig(\"gambar_data/mfcc/{}.png\".format(name[:-4]))\n",
    "    elif type == \"save_padded\":\n",
    "        plt.savefig(\"gambar_data/mfcc_padded/{}.png\".format(name[:-4]))\n",
    "    else:\n",
    "        return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_to_mfcc(mfcc_list[\"Name\"][1], padded_data, \"show\")\n",
    "# for x,y in zip(signal_list[\"Name\"],signal_list[\"Signal\"]):\n",
    "#     plot_to_waveform(x, y)\n",
    "# for x,y in zip(mfcc_list[\"Name\"],mfcc_list[\"Vector\"]):\n",
    "#     plot_to_mfcc(x, y, \"save\")\n",
    "# for x,y in zip(padded_mfcc_list[\"Name\"],padded_mfcc_list[\"Vector\"]):\n",
    "#     plot_to_mfcc(x, y, \"save_padded\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_model_1():\n",
    "    model = tf.keras.Sequential()\n",
    "    base_model = tf.keras.applications.resnet_v2.ResNet50V2(\n",
    "        include_top=False, weights=None, input_shape=(train_data_value.shape[1], train_data_value.shape[2], 1))\n",
    "    model.add(base_model)\n",
    "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten()))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)))\n",
    "    model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "    model.add(tf.keras.layers.Dense(6, activation=\"softmax\"))\n",
    "    optimiser = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimiser,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    csv_logger = tf.keras.callbacks.CSVLogger('resnet_unweighted.csv')\n",
    "    history = model.fit(train_data_value, train_data_target, validation_data=(\n",
    "        test_data_value, test_data_target), batch_size=64, epochs=30, callbacks=[csv_logger])\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_model_weighted():\n",
    "    train_data_value_reshaped = np.zeros((train_data_value.shape[0], train_data_value.shape[1], train_data_value.shape[2], 3))\n",
    "    train_data_value_reshaped[..., 0] = train_data_value\n",
    "    train_data_value_reshaped[..., 1] = train_data_value\n",
    "    train_data_value_reshaped[..., 2] = train_data_value\n",
    "    test_data_value_reshaped = np.zeros((test_data_value.shape[0], test_data_value.shape[1], test_data_value.shape[2], 3))\n",
    "    test_data_value_reshaped[..., 0] = test_data_value\n",
    "    test_data_value_reshaped[..., 1] = test_data_value\n",
    "    test_data_value_reshaped[..., 2] = test_data_value\n",
    "    model = tf.keras.Sequential()\n",
    "    base_model = tf.keras.applications.resnet_v2.ResNet50V2(\n",
    "        include_top=False, weights=\"imagenet\", input_shape=(train_data_value_reshaped.shape[1], train_data_value_reshaped.shape[2], 3))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model.add(base_model)\n",
    "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten()))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)))\n",
    "    model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "    model.add(tf.keras.layers.Dense(6, activation=\"softmax\"))\n",
    "    optimiser = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimiser,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    csv_logger = tf.keras.callbacks.CSVLogger('resnet_weighted.csv')\n",
    "    history = model.fit(train_data_value_reshaped, train_data_target, validation_data=(\n",
    "        test_data_value_reshaped, test_data_target), batch_size=64, epochs=30, callbacks=[csv_logger])\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_model_weighted_trainable():\n",
    "    train_data_value_reshaped = np.zeros((train_data_value.shape[0], train_data_value.shape[1], train_data_value.shape[2], 3))\n",
    "    train_data_value_reshaped[..., 0] = train_data_value\n",
    "    train_data_value_reshaped[..., 1] = train_data_value\n",
    "    train_data_value_reshaped[..., 2] = train_data_value\n",
    "    test_data_value_reshaped = np.zeros((test_data_value.shape[0], test_data_value.shape[1], test_data_value.shape[2], 3))\n",
    "    test_data_value_reshaped[..., 0] = test_data_value\n",
    "    test_data_value_reshaped[..., 1] = test_data_value\n",
    "    test_data_value_reshaped[..., 2] = test_data_value\n",
    "    model = tf.keras.Sequential()\n",
    "    base_model = tf.keras.applications.resnet_v2.ResNet50V2(\n",
    "        include_top=False, weights=\"imagenet\", input_shape=(train_data_value_reshaped.shape[1], train_data_value_reshaped.shape[2], 3))\n",
    "    model.add(base_model)\n",
    "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten()))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)))\n",
    "    model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "    model.add(tf.keras.layers.Dense(6, activation=\"softmax\"))\n",
    "    optimiser = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimiser,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    csv_logger = tf.keras.callbacks.CSVLogger('resnet_weighted_trainable.csv')\n",
    "    history = model.fit(train_data_value_reshaped, train_data_target, validation_data=(\n",
    "        test_data_value_reshaped, test_data_target), batch_size=64, epochs=30, callbacks=[csv_logger])\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94668760/94668760 [==============================] - 27s 0us/step\n",
      "Epoch 1/30\n",
      "94/94 [==============================] - 18s 113ms/step - loss: 1.7493 - accuracy: 0.2498 - val_loss: 1.7700 - val_accuracy: 0.2317\n",
      "Epoch 2/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.7463 - accuracy: 0.2476 - val_loss: 1.7292 - val_accuracy: 0.2565\n",
      "Epoch 3/30\n",
      "94/94 [==============================] - 8s 87ms/step - loss: 1.7161 - accuracy: 0.2699 - val_loss: 1.7046 - val_accuracy: 0.2760\n",
      "Epoch 4/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.7039 - accuracy: 0.2738 - val_loss: 1.6669 - val_accuracy: 0.2989\n",
      "Epoch 5/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6888 - accuracy: 0.2728 - val_loss: 1.6564 - val_accuracy: 0.3015\n",
      "Epoch 6/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6658 - accuracy: 0.3004 - val_loss: 1.6605 - val_accuracy: 0.2968\n",
      "Epoch 7/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6637 - accuracy: 0.2992 - val_loss: 1.6549 - val_accuracy: 0.2968\n",
      "Epoch 8/30\n",
      "94/94 [==============================] - 8s 87ms/step - loss: 1.6841 - accuracy: 0.2878 - val_loss: 1.6597 - val_accuracy: 0.2908\n",
      "Epoch 9/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6634 - accuracy: 0.2928 - val_loss: 1.6713 - val_accuracy: 0.2928\n",
      "Epoch 10/30\n",
      "94/94 [==============================] - 8s 87ms/step - loss: 1.6588 - accuracy: 0.3039 - val_loss: 1.6401 - val_accuracy: 0.3237\n",
      "Epoch 11/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6516 - accuracy: 0.3046 - val_loss: 1.6529 - val_accuracy: 0.2760\n",
      "Epoch 12/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6479 - accuracy: 0.3002 - val_loss: 1.6522 - val_accuracy: 0.2962\n",
      "Epoch 13/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6389 - accuracy: 0.3135 - val_loss: 1.6498 - val_accuracy: 0.2948\n",
      "Epoch 14/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6410 - accuracy: 0.3109 - val_loss: 1.6391 - val_accuracy: 0.3304\n",
      "Epoch 15/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6320 - accuracy: 0.3151 - val_loss: 1.6432 - val_accuracy: 0.3183\n",
      "Epoch 16/30\n",
      "94/94 [==============================] - 8s 85ms/step - loss: 1.6386 - accuracy: 0.3136 - val_loss: 1.6665 - val_accuracy: 0.2935\n",
      "Epoch 17/30\n",
      "94/94 [==============================] - 8s 85ms/step - loss: 1.6207 - accuracy: 0.3160 - val_loss: 1.6464 - val_accuracy: 0.2827\n",
      "Epoch 18/30\n",
      "94/94 [==============================] - 8s 85ms/step - loss: 1.6279 - accuracy: 0.3158 - val_loss: 1.6559 - val_accuracy: 0.3170\n",
      "Epoch 19/30\n",
      "94/94 [==============================] - 8s 85ms/step - loss: 1.6156 - accuracy: 0.3219 - val_loss: 1.6211 - val_accuracy: 0.3177\n",
      "Epoch 20/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6459 - accuracy: 0.3086 - val_loss: 1.6388 - val_accuracy: 0.3230\n",
      "Epoch 21/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6172 - accuracy: 0.3210 - val_loss: 1.6149 - val_accuracy: 0.3257\n",
      "Epoch 22/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6176 - accuracy: 0.3193 - val_loss: 1.6555 - val_accuracy: 0.2989\n",
      "Epoch 23/30\n",
      "94/94 [==============================] - 8s 85ms/step - loss: 1.6281 - accuracy: 0.3193 - val_loss: 1.6381 - val_accuracy: 0.3116\n",
      "Epoch 24/30\n",
      "94/94 [==============================] - 8s 85ms/step - loss: 1.6065 - accuracy: 0.3286 - val_loss: 1.6444 - val_accuracy: 0.3163\n",
      "Epoch 25/30\n",
      "94/94 [==============================] - 8s 85ms/step - loss: 1.6031 - accuracy: 0.3261 - val_loss: 1.6194 - val_accuracy: 0.3123\n",
      "Epoch 26/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6056 - accuracy: 0.3289 - val_loss: 1.6359 - val_accuracy: 0.3251\n",
      "Epoch 27/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6138 - accuracy: 0.3237 - val_loss: 1.7063 - val_accuracy: 0.2948\n",
      "Epoch 28/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.7128 - accuracy: 0.2716 - val_loss: 1.6941 - val_accuracy: 0.2760\n",
      "Epoch 29/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6661 - accuracy: 0.2945 - val_loss: 1.6687 - val_accuracy: 0.2942\n",
      "Epoch 30/30\n",
      "94/94 [==============================] - 8s 86ms/step - loss: 1.6420 - accuracy: 0.3151 - val_loss: 1.6614 - val_accuracy: 0.2928\n"
     ]
    }
   ],
   "source": [
    "resnet_model_weighted, resnet_weighted_history = resnet_model_weighted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "94/94 [==============================] - 37s 263ms/step - loss: 1.4502 - accuracy: 0.4090 - val_loss: 2.0030 - val_accuracy: 0.3304\n",
      "Epoch 2/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 1.3239 - accuracy: 0.4732 - val_loss: 2.4130 - val_accuracy: 0.2807\n",
      "Epoch 3/30\n",
      "94/94 [==============================] - 21s 222ms/step - loss: 1.2393 - accuracy: 0.5110 - val_loss: 2.5449 - val_accuracy: 0.3264\n",
      "Epoch 4/30\n",
      "94/94 [==============================] - 21s 222ms/step - loss: 1.1645 - accuracy: 0.5548 - val_loss: 2.3452 - val_accuracy: 0.3237\n",
      "Epoch 5/30\n",
      "94/94 [==============================] - 20s 217ms/step - loss: 1.1332 - accuracy: 0.5631 - val_loss: 2.5571 - val_accuracy: 0.2942\n",
      "Epoch 6/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 1.0692 - accuracy: 0.5935 - val_loss: 1.8947 - val_accuracy: 0.3660\n",
      "Epoch 7/30\n",
      "94/94 [==============================] - 21s 223ms/step - loss: 1.0230 - accuracy: 0.6135 - val_loss: 1.6168 - val_accuracy: 0.4768\n",
      "Epoch 8/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 1.0034 - accuracy: 0.6237 - val_loss: 2.9262 - val_accuracy: 0.2747\n",
      "Epoch 9/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 1.0382 - accuracy: 0.6089 - val_loss: 1.6370 - val_accuracy: 0.4298\n",
      "Epoch 10/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 0.9752 - accuracy: 0.6353 - val_loss: 2.8811 - val_accuracy: 0.2767\n",
      "Epoch 11/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 0.8678 - accuracy: 0.6876 - val_loss: 1.7977 - val_accuracy: 0.4480\n",
      "Epoch 12/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 0.8316 - accuracy: 0.6906 - val_loss: 1.3334 - val_accuracy: 0.5245\n",
      "Epoch 13/30\n",
      "94/94 [==============================] - 21s 222ms/step - loss: 0.7443 - accuracy: 0.7259 - val_loss: 1.6217 - val_accuracy: 0.4600\n",
      "Epoch 14/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 0.6874 - accuracy: 0.7552 - val_loss: 1.3522 - val_accuracy: 0.5453\n",
      "Epoch 15/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 0.6341 - accuracy: 0.7712 - val_loss: 1.5342 - val_accuracy: 0.5017\n",
      "Epoch 16/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 0.5624 - accuracy: 0.7994 - val_loss: 2.0656 - val_accuracy: 0.4466\n",
      "Epoch 17/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 0.5230 - accuracy: 0.8140 - val_loss: 2.1100 - val_accuracy: 0.4600\n",
      "Epoch 18/30\n",
      "94/94 [==============================] - 21s 222ms/step - loss: 0.6306 - accuracy: 0.7675 - val_loss: 1.8267 - val_accuracy: 0.4943\n",
      "Epoch 19/30\n",
      "94/94 [==============================] - 21s 223ms/step - loss: 0.5728 - accuracy: 0.7914 - val_loss: 1.5476 - val_accuracy: 0.5581\n",
      "Epoch 20/30\n",
      "94/94 [==============================] - 21s 227ms/step - loss: 0.4094 - accuracy: 0.8539 - val_loss: 1.6255 - val_accuracy: 0.5373\n",
      "Epoch 21/30\n",
      "94/94 [==============================] - 21s 224ms/step - loss: 0.3334 - accuracy: 0.8859 - val_loss: 1.5598 - val_accuracy: 0.5594\n",
      "Epoch 22/30\n",
      "94/94 [==============================] - 21s 222ms/step - loss: 0.3405 - accuracy: 0.8873 - val_loss: 1.5846 - val_accuracy: 0.5520\n",
      "Epoch 23/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 0.2904 - accuracy: 0.9002 - val_loss: 1.9632 - val_accuracy: 0.5218\n",
      "Epoch 24/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 0.2683 - accuracy: 0.9091 - val_loss: 1.8678 - val_accuracy: 0.5299\n",
      "Epoch 25/30\n",
      "94/94 [==============================] - 21s 222ms/step - loss: 0.2489 - accuracy: 0.9145 - val_loss: 1.6947 - val_accuracy: 0.5581\n",
      "Epoch 26/30\n",
      "94/94 [==============================] - 21s 223ms/step - loss: 0.2061 - accuracy: 0.9313 - val_loss: 2.2835 - val_accuracy: 0.5178\n",
      "Epoch 27/30\n",
      "94/94 [==============================] - 21s 223ms/step - loss: 0.2135 - accuracy: 0.9263 - val_loss: 2.1661 - val_accuracy: 0.5413\n",
      "Epoch 28/30\n",
      "94/94 [==============================] - 21s 223ms/step - loss: 0.1918 - accuracy: 0.9340 - val_loss: 1.8123 - val_accuracy: 0.5601\n",
      "Epoch 29/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 0.1669 - accuracy: 0.9449 - val_loss: 2.1418 - val_accuracy: 0.5561\n",
      "Epoch 30/30\n",
      "94/94 [==============================] - 21s 223ms/step - loss: 0.1644 - accuracy: 0.9457 - val_loss: 2.0548 - val_accuracy: 0.5588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 57). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet_model_trainable_weight\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet_model_trainable_weight\\assets\n"
     ]
    }
   ],
   "source": [
    "resnet_model_weighted_trainable, resnet_weighted_trainable_history = resnet_model_weighted_trainable()\n",
    "resnet_model_weighted_trainable.save(\"resnet_model_trainable_weight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "94/94 [==============================] - 32s 252ms/step - loss: 1.5680 - accuracy: 0.3430 - val_loss: 3.0238 - val_accuracy: 0.1706\n",
      "Epoch 2/30\n",
      "94/94 [==============================] - 21s 225ms/step - loss: 1.4434 - accuracy: 0.4070 - val_loss: 3.1265 - val_accuracy: 0.1706\n",
      "Epoch 3/30\n",
      "94/94 [==============================] - 21s 222ms/step - loss: 1.3606 - accuracy: 0.4572 - val_loss: 3.7027 - val_accuracy: 0.1706\n",
      "Epoch 4/30\n",
      "94/94 [==============================] - 21s 224ms/step - loss: 1.3887 - accuracy: 0.4393 - val_loss: 2.7338 - val_accuracy: 0.2445\n",
      "Epoch 5/30\n",
      "94/94 [==============================] - 21s 223ms/step - loss: 1.3273 - accuracy: 0.4720 - val_loss: 2.4987 - val_accuracy: 0.3674\n",
      "Epoch 6/30\n",
      "94/94 [==============================] - 21s 225ms/step - loss: 1.2750 - accuracy: 0.5004 - val_loss: 1.5170 - val_accuracy: 0.3714\n",
      "Epoch 7/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 1.3947 - accuracy: 0.4368 - val_loss: 1.9422 - val_accuracy: 0.3150\n",
      "Epoch 8/30\n",
      "94/94 [==============================] - 21s 219ms/step - loss: 1.2916 - accuracy: 0.4883 - val_loss: 2.6914 - val_accuracy: 0.2048\n",
      "Epoch 9/30\n",
      "94/94 [==============================] - 21s 219ms/step - loss: 1.3437 - accuracy: 0.4567 - val_loss: 2.7050 - val_accuracy: 0.1786\n",
      "Epoch 10/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 1.2716 - accuracy: 0.4979 - val_loss: 2.1390 - val_accuracy: 0.2807\n",
      "Epoch 11/30\n",
      "94/94 [==============================] - 21s 219ms/step - loss: 1.2003 - accuracy: 0.5234 - val_loss: 1.4502 - val_accuracy: 0.4426\n",
      "Epoch 12/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 1.1830 - accuracy: 0.5317 - val_loss: 1.4247 - val_accuracy: 0.4500\n",
      "Epoch 13/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 1.2358 - accuracy: 0.5150 - val_loss: 1.3557 - val_accuracy: 0.4493\n",
      "Epoch 14/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 1.1609 - accuracy: 0.5414 - val_loss: 1.7824 - val_accuracy: 0.3284\n",
      "Epoch 15/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 1.1423 - accuracy: 0.5506 - val_loss: 1.5204 - val_accuracy: 0.4090\n",
      "Epoch 16/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 1.1553 - accuracy: 0.5456 - val_loss: 1.3067 - val_accuracy: 0.5158\n",
      "Epoch 17/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 1.1047 - accuracy: 0.5688 - val_loss: 1.7285 - val_accuracy: 0.3358\n",
      "Epoch 18/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 1.1093 - accuracy: 0.5644 - val_loss: 1.9176 - val_accuracy: 0.3909\n",
      "Epoch 19/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 1.1047 - accuracy: 0.5636 - val_loss: 1.9505 - val_accuracy: 0.4063\n",
      "Epoch 20/30\n",
      "94/94 [==============================] - 21s 219ms/step - loss: 1.0685 - accuracy: 0.5869 - val_loss: 1.5647 - val_accuracy: 0.4459\n",
      "Epoch 21/30\n",
      "94/94 [==============================] - 21s 219ms/step - loss: 1.0680 - accuracy: 0.5940 - val_loss: 1.9083 - val_accuracy: 0.3318\n",
      "Epoch 22/30\n",
      "94/94 [==============================] - 21s 219ms/step - loss: 1.1105 - accuracy: 0.5654 - val_loss: 1.5782 - val_accuracy: 0.4365\n",
      "Epoch 23/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 1.2491 - accuracy: 0.5098 - val_loss: 1.4268 - val_accuracy: 0.4547\n",
      "Epoch 24/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 1.2008 - accuracy: 0.5278 - val_loss: 1.3050 - val_accuracy: 0.4849\n",
      "Epoch 25/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 1.1164 - accuracy: 0.5681 - val_loss: 1.3483 - val_accuracy: 0.4876\n",
      "Epoch 26/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 1.0765 - accuracy: 0.5770 - val_loss: 1.1545 - val_accuracy: 0.5467\n",
      "Epoch 27/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 1.0377 - accuracy: 0.5985 - val_loss: 1.3472 - val_accuracy: 0.5212\n",
      "Epoch 28/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 1.0033 - accuracy: 0.6148 - val_loss: 1.2651 - val_accuracy: 0.5252\n",
      "Epoch 29/30\n",
      "94/94 [==============================] - 21s 221ms/step - loss: 1.0106 - accuracy: 0.6115 - val_loss: 1.4671 - val_accuracy: 0.4560\n",
      "Epoch 30/30\n",
      "94/94 [==============================] - 21s 220ms/step - loss: 1.0848 - accuracy: 0.5794 - val_loss: 1.2826 - val_accuracy: 0.5285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 57). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet_model_unweighted\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet_model_unweighted\\assets\n"
     ]
    }
   ],
   "source": [
    "resnet_model_unweighted, resnet_unweighted_history = resnet_model_1()\n",
    "resnet_model_unweighted.save(\"resnet_model_unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 57). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet_model_unweighted\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet_model_unweighted\\assets\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 57). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet_model_weighted\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet_model_weighted\\assets\n"
     ]
    }
   ],
   "source": [
    "resnet_model_weighted.save(\"resnet_model_weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
