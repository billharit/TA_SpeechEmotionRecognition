{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from dataset import load_to_dataframe, turn_into_data_for_model, get_sample_rate\n",
    "from model import train_cnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size:0\n",
      "Train Size:300\n",
      "Train Size:600\n",
      "Train Size:900\n",
      "Train Size:1200\n",
      "Train Size:1500\n",
      "Train Size:1800\n",
      "Train Size:2100\n",
      "Train Size:2400\n",
      "Train Size:2700\n",
      "Train Size:3000\n",
      "Train Size:3300\n",
      "Train Size:3600\n",
      "Train Size:3900\n",
      "Train Size:4200\n",
      "Train Size:4500\n",
      "Train Size:4800\n",
      "Train Size:5100\n",
      "Train Size:5400\n",
      "Train Size:5700\n",
      "Test Size:0\n",
      "Test Size:300\n",
      "Test Size:600\n",
      "Test Size:900\n",
      "Test Size:1200\n",
      "(5953, 156, 40)\n",
      "(1489, 156, 40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\TA-Bill\\dataset.py:139: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_data_value = np.asarray(train_data['mfcc'])\n",
      "e:\\TA-Bill\\dataset.py:143: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  test_data_value = np.asarray(test_data['mfcc'])\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = load_to_dataframe('dataset/train', 'dataset/test')\n",
    "train_data_value, train_data_target, test_data_value, test_data_target = turn_into_data_for_model(\n",
    "    train_df, test_df, 40, 2048, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"crema_d_f32_train_data_value\", train_data_value)\n",
    "np.save(\"crema_d_f32_train_data_target\", train_data_target)\n",
    "np.save(\"crema_d_f32_test_data_value\", test_data_value)\n",
    "np.save(\"crema_d_f32_test_data_target\", test_data_target)\n",
    "\n",
    "# train_data_value = np.load('saved_dataset/40_2048_512_train_data_value.npy')\n",
    "# train_data_target = np.load('saved_dataset/40_2048_512_train_data_target.npy')\n",
    "# test_data_value = np.load('saved_dataset/40_2048_512_test_data_value.npy')\n",
    "# test_data_target = np.load('saved_dataset/40_2048_512_test_data_target.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.resnet50.ResNet50(\n",
    "    include_top=True, weights=None, input_shape=(train_data_value.shape[1], train_data_value.shape[2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 156, 40, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 162, 46, 1)   0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 78, 20, 64)   3200        ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 78, 20, 64)   256         ['conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 78, 20, 64)   0           ['conv1_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 80, 22, 64)   0           ['conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 39, 10, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 39, 10, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 39, 10, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 39, 10, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 39, 10, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 39, 10, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 39, 10, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 39, 10, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 39, 10, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 39, 10, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 39, 10, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 39, 10, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 39, 10, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 39, 10, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 39, 10, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 39, 10, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 39, 10, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 39, 10, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 39, 10, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 39, 10, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 39, 10, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 39, 10, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 39, 10, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 39, 10, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 39, 10, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 39, 10, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 39, 10, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 39, 10, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 39, 10, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 39, 10, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 39, 10, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 39, 10, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 39, 10, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 20, 5, 128)   32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 20, 5, 128)  512         ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 20, 5, 128)  0           ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 20, 5, 128)   147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 20, 5, 128)  512         ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 20, 5, 128)  0           ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 20, 5, 512)   131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 20, 5, 512)   66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 20, 5, 512)  2048        ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 20, 5, 512)  2048        ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 20, 5, 512)   0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 20, 5, 512)   0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 20, 5, 128)   65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 20, 5, 128)  512         ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 20, 5, 128)  0           ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 20, 5, 128)   147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 20, 5, 128)  512         ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 20, 5, 128)  0           ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 20, 5, 512)   66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 20, 5, 512)  2048        ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 20, 5, 512)   0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 20, 5, 512)   0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 20, 5, 128)   65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 20, 5, 128)  512         ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 20, 5, 128)  0           ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 20, 5, 128)   147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 20, 5, 128)  512         ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 20, 5, 128)  0           ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 20, 5, 512)   66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 20, 5, 512)  2048        ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 20, 5, 512)   0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 20, 5, 512)   0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 20, 5, 128)   65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 20, 5, 128)  512         ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 20, 5, 128)  0           ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 20, 5, 128)   147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 20, 5, 128)  512         ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 20, 5, 128)  0           ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 20, 5, 512)   66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 20, 5, 512)  2048        ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 20, 5, 512)   0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 20, 5, 512)   0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 10, 3, 256)   131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 10, 3, 256)  1024        ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 10, 3, 256)  0           ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 10, 3, 256)   590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 10, 3, 256)  1024        ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 10, 3, 256)  0           ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 10, 3, 1024)  525312      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 10, 3, 1024)  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 10, 3, 1024)  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 10, 3, 1024)  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 10, 3, 1024)  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                                                  'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 10, 3, 1024)  0           ['conv4_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 10, 3, 256)   262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 10, 3, 256)  1024        ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 10, 3, 256)  0           ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 10, 3, 256)   590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 10, 3, 256)  1024        ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 10, 3, 256)  0           ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 10, 3, 1024)  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 10, 3, 1024)  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 10, 3, 1024)  0           ['conv4_block1_out[0][0]',       \n",
      "                                                                  'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 10, 3, 1024)  0           ['conv4_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 10, 3, 256)   262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 10, 3, 256)  1024        ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 10, 3, 256)  0           ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 10, 3, 256)   590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 10, 3, 256)  1024        ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 10, 3, 256)  0           ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 10, 3, 1024)  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 10, 3, 1024)  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 10, 3, 1024)  0           ['conv4_block2_out[0][0]',       \n",
      "                                                                  'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 10, 3, 1024)  0           ['conv4_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 10, 3, 256)   262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 10, 3, 256)  1024        ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 10, 3, 256)  0           ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 10, 3, 256)   590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 10, 3, 256)  1024        ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 10, 3, 256)  0           ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 10, 3, 1024)  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 10, 3, 1024)  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 10, 3, 1024)  0           ['conv4_block3_out[0][0]',       \n",
      "                                                                  'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 10, 3, 1024)  0           ['conv4_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 10, 3, 256)   262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 10, 3, 256)  1024        ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 10, 3, 256)  0           ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 10, 3, 256)   590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 10, 3, 256)  1024        ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 10, 3, 256)  0           ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 10, 3, 1024)  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 10, 3, 1024)  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 10, 3, 1024)  0           ['conv4_block4_out[0][0]',       \n",
      "                                                                  'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 10, 3, 1024)  0           ['conv4_block5_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 10, 3, 256)   262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 10, 3, 256)  1024        ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 10, 3, 256)  0           ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 10, 3, 256)   590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 10, 3, 256)  1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 10, 3, 256)  0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 10, 3, 1024)  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 10, 3, 1024)  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 10, 3, 1024)  0           ['conv4_block5_out[0][0]',       \n",
      "                                                                  'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 10, 3, 1024)  0           ['conv4_block6_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 5, 2, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 5, 2, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 5, 2, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 5, 2, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 5, 2, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 5, 2, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 5, 2, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 5, 2, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 5, 2, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 5, 2, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 5, 2, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 5, 2, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 5, 2, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 5, 2, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 5, 2, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 5, 2, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 5, 2, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 5, 2, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 5, 2, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 5, 2, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 5, 2, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 5, 2, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 5, 2, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 5, 2, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 5, 2, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 5, 2, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 5, 2, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 5, 2, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 5, 2, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 5, 2, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 5, 2, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 5, 2, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " predictions (Dense)            (None, 1000)         2049000     ['avg_pool[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25,630,440\n",
      "Trainable params: 25,577,320\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 5, 2, 2048)        23581440  \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 20480)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1024)              20972544  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 6)                 6150      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,560,134\n",
      "Trainable params: 44,507,014\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_model = tf.keras.Sequential()\n",
    "base_model = tf.keras.applications.resnet50.ResNet50(\n",
    "    include_top=False, weights=None, input_shape=(train_data_value.shape[1], train_data_value.shape[2], 1))\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "resnet_model.add(base_model)\n",
    "resnet_model.add(tf.keras.layers.Flatten())\n",
    "resnet_model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "resnet_model.add(tf.keras.layers.Dropout(0.3))\n",
    "resnet_model.add(tf.keras.layers.Dense(6, activation=\"softmax\"))\n",
    "resnet_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "resnet_model.compile(optimizer=optimiser,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "187/187 [==============================] - 37s 163ms/step - loss: 5.8938 - accuracy: 0.2795 - val_loss: 1.6016 - val_accuracy: 0.2995\n",
      "Epoch 2/20\n",
      "187/187 [==============================] - 29s 158ms/step - loss: 1.5474 - accuracy: 0.3501 - val_loss: 1.6009 - val_accuracy: 0.3277\n",
      "Epoch 3/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.5194 - accuracy: 0.3854 - val_loss: 1.5238 - val_accuracy: 0.3694\n",
      "Epoch 4/20\n",
      "187/187 [==============================] - 30s 159ms/step - loss: 1.4555 - accuracy: 0.4208 - val_loss: 1.4238 - val_accuracy: 0.4171\n",
      "Epoch 5/20\n",
      "187/187 [==============================] - 30s 158ms/step - loss: 1.4520 - accuracy: 0.4173 - val_loss: 1.4145 - val_accuracy: 0.4540\n",
      "Epoch 6/20\n",
      "187/187 [==============================] - 30s 159ms/step - loss: 1.4348 - accuracy: 0.4292 - val_loss: 1.6656 - val_accuracy: 0.3224\n",
      "Epoch 7/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.3824 - accuracy: 0.4571 - val_loss: 1.3151 - val_accuracy: 0.4889\n",
      "Epoch 8/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.3090 - accuracy: 0.4959 - val_loss: 1.2625 - val_accuracy: 0.4909\n",
      "Epoch 9/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.3023 - accuracy: 0.4955 - val_loss: 1.7303 - val_accuracy: 0.2565\n",
      "Epoch 10/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.4903 - accuracy: 0.4153 - val_loss: 2.1136 - val_accuracy: 0.2337\n",
      "Epoch 11/20\n",
      "187/187 [==============================] - 30s 159ms/step - loss: 1.3433 - accuracy: 0.4816 - val_loss: 1.4016 - val_accuracy: 0.4513\n",
      "Epoch 12/20\n",
      "187/187 [==============================] - 30s 159ms/step - loss: 1.2943 - accuracy: 0.5053 - val_loss: 1.3374 - val_accuracy: 0.4882\n",
      "Epoch 13/20\n",
      "187/187 [==============================] - 29s 156ms/step - loss: 1.2420 - accuracy: 0.5212 - val_loss: 2.1253 - val_accuracy: 0.3358\n",
      "Epoch 14/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.3140 - accuracy: 0.4992 - val_loss: 2.0596 - val_accuracy: 0.3002\n",
      "Epoch 15/20\n",
      "187/187 [==============================] - 30s 158ms/step - loss: 1.4743 - accuracy: 0.4111 - val_loss: 1.6350 - val_accuracy: 0.3573\n",
      "Epoch 16/20\n",
      "187/187 [==============================] - 29s 158ms/step - loss: 1.3438 - accuracy: 0.4727 - val_loss: 1.3785 - val_accuracy: 0.4654\n",
      "Epoch 17/20\n",
      "187/187 [==============================] - 30s 158ms/step - loss: 1.3469 - accuracy: 0.4796 - val_loss: 2.8094 - val_accuracy: 0.1934\n",
      "Epoch 18/20\n",
      "187/187 [==============================] - 30s 159ms/step - loss: 1.3296 - accuracy: 0.4989 - val_loss: 1.7028 - val_accuracy: 0.3049\n",
      "Epoch 19/20\n",
      "187/187 [==============================] - 29s 158ms/step - loss: 1.4707 - accuracy: 0.4181 - val_loss: 1.2942 - val_accuracy: 0.4990\n",
      "Epoch 20/20\n",
      "187/187 [==============================] - 30s 158ms/step - loss: 1.3208 - accuracy: 0.4735 - val_loss: 1.5391 - val_accuracy: 0.3781\n"
     ]
    }
   ],
   "source": [
    "resnet_history = resnet_model.fit(train_data_value, train_data_target, validation_data=(\n",
    "    test_data_value, test_data_target), batch_size=32, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "187/187 [==============================] - 29s 156ms/step - loss: 1.2603 - accuracy: 0.4979 - val_loss: 1.5322 - val_accuracy: 0.4238\n",
      "Epoch 2/20\n",
      "187/187 [==============================] - 29s 156ms/step - loss: 1.2283 - accuracy: 0.5130 - val_loss: 1.3211 - val_accuracy: 0.4681\n",
      "Epoch 3/20\n",
      "187/187 [==============================] - 29s 156ms/step - loss: 1.2303 - accuracy: 0.5139 - val_loss: 2.9873 - val_accuracy: 0.3741\n",
      "Epoch 4/20\n",
      "187/187 [==============================] - 29s 156ms/step - loss: 1.2337 - accuracy: 0.5186 - val_loss: 1.3687 - val_accuracy: 0.4708\n",
      "Epoch 5/20\n",
      "187/187 [==============================] - 29s 156ms/step - loss: 1.2613 - accuracy: 0.5083 - val_loss: 1.6462 - val_accuracy: 0.3674\n",
      "Epoch 6/20\n",
      "187/187 [==============================] - 29s 156ms/step - loss: 1.3106 - accuracy: 0.4866 - val_loss: 1.9762 - val_accuracy: 0.1719\n",
      "Epoch 7/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.4312 - accuracy: 0.4292 - val_loss: 1.8307 - val_accuracy: 0.3257\n",
      "Epoch 8/20\n",
      "187/187 [==============================] - 30s 158ms/step - loss: 1.3721 - accuracy: 0.4616 - val_loss: 3.3499 - val_accuracy: 0.1854\n",
      "Epoch 9/20\n",
      "187/187 [==============================] - 30s 158ms/step - loss: 1.2751 - accuracy: 0.4996 - val_loss: 1.4116 - val_accuracy: 0.4453\n",
      "Epoch 10/20\n",
      "187/187 [==============================] - 30s 158ms/step - loss: 1.2858 - accuracy: 0.5031 - val_loss: 1.8014 - val_accuracy: 0.1713\n",
      "Epoch 11/20\n",
      "187/187 [==============================] - 30s 158ms/step - loss: 1.3721 - accuracy: 0.4515 - val_loss: 1.8005 - val_accuracy: 0.3264\n",
      "Epoch 12/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.3691 - accuracy: 0.4494 - val_loss: 1.4773 - val_accuracy: 0.4083\n",
      "Epoch 13/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.3274 - accuracy: 0.4662 - val_loss: 1.3357 - val_accuracy: 0.4500\n",
      "Epoch 14/20\n",
      "187/187 [==============================] - 29s 156ms/step - loss: 1.3964 - accuracy: 0.4394 - val_loss: 1.5595 - val_accuracy: 0.3546\n",
      "Epoch 15/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.2813 - accuracy: 0.4969 - val_loss: 2.0572 - val_accuracy: 0.3539\n",
      "Epoch 16/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.2306 - accuracy: 0.5296 - val_loss: 1.2607 - val_accuracy: 0.5024\n",
      "Epoch 17/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.3239 - accuracy: 0.4900 - val_loss: 1.7283 - val_accuracy: 0.3049\n",
      "Epoch 18/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.2176 - accuracy: 0.5201 - val_loss: 1.4068 - val_accuracy: 0.4291\n",
      "Epoch 19/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.1783 - accuracy: 0.5391 - val_loss: 1.2814 - val_accuracy: 0.4681\n",
      "Epoch 20/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.2139 - accuracy: 0.5243 - val_loss: 2.2799 - val_accuracy: 0.3056\n"
     ]
    }
   ],
   "source": [
    "resnet_history = resnet_model.fit(train_data_value, train_data_target, validation_data=(\n",
    "    test_data_value, test_data_target), batch_size=64, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "resnet_model.compile(optimizer=optimiser,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "187/187 [==============================] - 16s 66ms/step - loss: 1.7902 - accuracy: 0.1700 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 2/20\n",
      "187/187 [==============================] - 11s 60ms/step - loss: 1.7902 - accuracy: 0.1643 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 3/20\n",
      "187/187 [==============================] - 11s 59ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 4/20\n",
      "187/187 [==============================] - 11s 57ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 5/20\n",
      "187/187 [==============================] - 11s 59ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 6/20\n",
      "187/187 [==============================] - 11s 59ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 7/20\n",
      "187/187 [==============================] - 11s 59ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 8/20\n",
      "187/187 [==============================] - 12s 62ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 9/20\n",
      "187/187 [==============================] - 11s 61ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 10/20\n",
      "187/187 [==============================] - 11s 60ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 11/20\n",
      "187/187 [==============================] - 11s 60ms/step - loss: 1.7902 - accuracy: 0.1697 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 12/20\n",
      "187/187 [==============================] - 11s 60ms/step - loss: 1.7902 - accuracy: 0.1690 - val_loss: 1.7902 - val_accuracy: 0.1713\n",
      "Epoch 13/20\n",
      "187/187 [==============================] - 11s 60ms/step - loss: 1.7902 - accuracy: 0.1623 - val_loss: 1.7902 - val_accuracy: 0.1713\n",
      "Epoch 14/20\n",
      "187/187 [==============================] - 12s 64ms/step - loss: 1.7902 - accuracy: 0.1702 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 15/20\n",
      "187/187 [==============================] - 11s 60ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 16/20\n",
      "187/187 [==============================] - 11s 60ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 17/20\n",
      "187/187 [==============================] - 11s 60ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 18/20\n",
      "187/187 [==============================] - 11s 60ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 19/20\n",
      "187/187 [==============================] - 11s 60ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 20/20\n",
      "187/187 [==============================] - 11s 59ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n"
     ]
    }
   ],
   "source": [
    "resnet_history2 = resnet_model.fit(train_data_value, train_data_target, validation_data=(\n",
    "    test_data_value, test_data_target), batch_size=32, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 154, 38, 128)      1280      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 77, 19, 128)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 77, 19, 128)      512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 75, 17, 64)        73792     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 38, 9, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 38, 9, 64)        256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 37, 8, 32)         8224      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 19, 4, 32)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 19, 4, 32)        128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2432)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                155712    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 240,294\n",
      "Trainable params: 239,846\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "187/187 [==============================] - 9s 36ms/step - loss: 1.7193 - accuracy: 0.2936 - val_loss: 1.4846 - val_accuracy: 0.3895\n",
      "Epoch 2/20\n",
      "187/187 [==============================] - 6s 34ms/step - loss: 1.4957 - accuracy: 0.3736 - val_loss: 1.4057 - val_accuracy: 0.4070\n",
      "Epoch 3/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 1.4332 - accuracy: 0.4109 - val_loss: 1.3681 - val_accuracy: 0.4399\n",
      "Epoch 4/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 1.3689 - accuracy: 0.4460 - val_loss: 1.3300 - val_accuracy: 0.4634\n",
      "Epoch 5/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 1.3121 - accuracy: 0.4730 - val_loss: 1.3236 - val_accuracy: 0.4647\n",
      "Epoch 6/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 1.2605 - accuracy: 0.4991 - val_loss: 1.2730 - val_accuracy: 0.4849\n",
      "Epoch 7/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 1.2150 - accuracy: 0.5192 - val_loss: 1.2489 - val_accuracy: 0.5010\n",
      "Epoch 8/20\n",
      "187/187 [==============================] - 6s 35ms/step - loss: 1.1822 - accuracy: 0.5302 - val_loss: 1.2250 - val_accuracy: 0.5158\n",
      "Epoch 9/20\n",
      "187/187 [==============================] - 6s 34ms/step - loss: 1.1293 - accuracy: 0.5560 - val_loss: 1.2221 - val_accuracy: 0.5279\n",
      "Epoch 10/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 1.1296 - accuracy: 0.5543 - val_loss: 1.2569 - val_accuracy: 0.5017\n",
      "Epoch 11/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 1.0454 - accuracy: 0.5970 - val_loss: 1.2657 - val_accuracy: 0.4923\n",
      "Epoch 12/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 1.0171 - accuracy: 0.6101 - val_loss: 1.2266 - val_accuracy: 0.5259\n",
      "Epoch 13/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 0.9776 - accuracy: 0.6288 - val_loss: 1.1827 - val_accuracy: 0.5400\n",
      "Epoch 14/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 0.9577 - accuracy: 0.6341 - val_loss: 1.1684 - val_accuracy: 0.5447\n",
      "Epoch 15/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 0.8999 - accuracy: 0.6583 - val_loss: 1.1564 - val_accuracy: 0.5487\n",
      "Epoch 16/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 0.8634 - accuracy: 0.6726 - val_loss: 1.2032 - val_accuracy: 0.5480\n",
      "Epoch 17/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 0.8228 - accuracy: 0.6983 - val_loss: 1.1556 - val_accuracy: 0.5541\n",
      "Epoch 18/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 0.7879 - accuracy: 0.7096 - val_loss: 1.1893 - val_accuracy: 0.5581\n",
      "Epoch 19/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 0.7377 - accuracy: 0.7233 - val_loss: 1.1791 - val_accuracy: 0.5641\n",
      "Epoch 20/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 0.7038 - accuracy: 0.7437 - val_loss: 1.1751 - val_accuracy: 0.5735\n"
     ]
    }
   ],
   "source": [
    "cnn_model = tf.keras.Sequential()\n",
    "cnn_model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=(\n",
    "    train_data_value.shape[1], train_data_value.shape[2], 1)))\n",
    "cnn_model.add(tf.keras.layers.MaxPooling2D(\n",
    "    (3, 3), strides=(2, 2), padding='same'))\n",
    "cnn_model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# 2nd conv layer\n",
    "cnn_model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn_model.add(tf.keras.layers.MaxPooling2D(\n",
    "    (3, 3), strides=(2, 2), padding='same'))\n",
    "cnn_model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# 3rd conv layer\n",
    "cnn_model.add(tf.keras.layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "cnn_model.add(tf.keras.layers.MaxPooling2D(\n",
    "    (2, 2), strides=(2, 2), padding='same'))\n",
    "cnn_model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# flatten output and feed it into dense layer\n",
    "cnn_model.add(tf.keras.layers.Flatten())\n",
    "cnn_model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "cnn_model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "cnn_model.add(tf.keras.layers.Dense(6, activation='softmax'))\n",
    "optimiser = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "cnn_model.summary()\n",
    "cnn_model.compile(optimizer=optimiser,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "history = cnn_model.fit(train_data_value, train_data_target, validation_data=(\n",
    "    test_data_value, test_data_target), batch_size=32, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 154, 38, 128)      1280      \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 152, 36, 128)      147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 76, 18, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 76, 18, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 74, 16, 64)        73792     \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 72, 14, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 70, 12, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 35, 6, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 35, 6, 64)        256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 34, 5, 32)         8224      \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 33, 4, 32)         4128      \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 32, 3, 32)         4128      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 16, 2, 32)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 16, 2, 32)        128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                65600     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 379,878\n",
      "Trainable params: 379,430\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "187/187 [==============================] - 17s 83ms/step - loss: 1.8806 - accuracy: 0.2493 - val_loss: 1.6707 - val_accuracy: 0.2807\n",
      "Epoch 2/20\n",
      "187/187 [==============================] - 14s 74ms/step - loss: 1.6171 - accuracy: 0.3375 - val_loss: 1.5491 - val_accuracy: 0.3694\n",
      "Epoch 3/20\n",
      "187/187 [==============================] - 14s 72ms/step - loss: 1.5307 - accuracy: 0.3738 - val_loss: 1.4770 - val_accuracy: 0.3956\n",
      "Epoch 4/20\n",
      "187/187 [==============================] - 14s 73ms/step - loss: 1.4633 - accuracy: 0.4055 - val_loss: 1.4084 - val_accuracy: 0.4251\n",
      "Epoch 5/20\n",
      "187/187 [==============================] - 14s 74ms/step - loss: 1.4151 - accuracy: 0.4262 - val_loss: 1.3938 - val_accuracy: 0.4426\n",
      "Epoch 6/20\n",
      "187/187 [==============================] - 14s 74ms/step - loss: 1.3592 - accuracy: 0.4536 - val_loss: 1.3308 - val_accuracy: 0.4681\n",
      "Epoch 7/20\n",
      "187/187 [==============================] - 14s 74ms/step - loss: 1.2960 - accuracy: 0.4784 - val_loss: 1.3077 - val_accuracy: 0.4762\n",
      "Epoch 8/20\n",
      "187/187 [==============================] - 14s 74ms/step - loss: 1.2627 - accuracy: 0.5048 - val_loss: 1.3324 - val_accuracy: 0.4788\n",
      "Epoch 9/20\n",
      "187/187 [==============================] - 14s 74ms/step - loss: 1.2179 - accuracy: 0.5270 - val_loss: 1.2489 - val_accuracy: 0.5097\n",
      "Epoch 10/20\n",
      "187/187 [==============================] - 14s 74ms/step - loss: 1.2034 - accuracy: 0.5254 - val_loss: 1.2514 - val_accuracy: 0.4943\n",
      "Epoch 11/20\n",
      "187/187 [==============================] - 14s 73ms/step - loss: 1.1569 - accuracy: 0.5513 - val_loss: 1.3698 - val_accuracy: 0.4614\n",
      "Epoch 12/20\n",
      "187/187 [==============================] - 14s 74ms/step - loss: 1.1089 - accuracy: 0.5701 - val_loss: 1.3010 - val_accuracy: 0.4668\n",
      "Epoch 13/20\n",
      "187/187 [==============================] - 14s 73ms/step - loss: 1.0869 - accuracy: 0.5775 - val_loss: 1.1941 - val_accuracy: 0.5299\n",
      "Epoch 14/20\n",
      "187/187 [==============================] - 14s 74ms/step - loss: 1.0600 - accuracy: 0.5868 - val_loss: 1.2328 - val_accuracy: 0.5131\n",
      "Epoch 15/20\n",
      "187/187 [==============================] - 14s 74ms/step - loss: 1.0906 - accuracy: 0.5814 - val_loss: 1.2258 - val_accuracy: 0.5245\n",
      "Epoch 16/20\n",
      "187/187 [==============================] - 14s 75ms/step - loss: 1.0213 - accuracy: 0.6052 - val_loss: 1.2204 - val_accuracy: 0.5252\n",
      "Epoch 17/20\n",
      "187/187 [==============================] - 14s 75ms/step - loss: 0.9469 - accuracy: 0.6286 - val_loss: 1.3283 - val_accuracy: 0.4835\n",
      "Epoch 18/20\n",
      "187/187 [==============================] - 14s 74ms/step - loss: 0.9017 - accuracy: 0.6546 - val_loss: 1.1951 - val_accuracy: 0.5252\n",
      "Epoch 19/20\n",
      "187/187 [==============================] - 14s 74ms/step - loss: 0.9248 - accuracy: 0.6494 - val_loss: 1.2148 - val_accuracy: 0.5252\n",
      "Epoch 20/20\n",
      "187/187 [==============================] - 14s 74ms/step - loss: 0.9066 - accuracy: 0.6556 - val_loss: 1.1798 - val_accuracy: 0.5473\n"
     ]
    }
   ],
   "source": [
    "cnn_model2 = tf.keras.Sequential()\n",
    "cnn_model2.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=(\n",
    "    train_data_value.shape[1], train_data_value.shape[2], 1)))\n",
    "cnn_model2.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "cnn_model2.add(tf.keras.layers.MaxPooling2D(\n",
    "    (3, 3), strides=(2, 2), padding='same'))\n",
    "cnn_model2.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# 2nd conv layer\n",
    "cnn_model2.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn_model2.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn_model2.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn_model2.add(tf.keras.layers.MaxPooling2D(\n",
    "    (3, 3), strides=(2, 2), padding='same'))\n",
    "cnn_model2.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# 3rd conv layer\n",
    "cnn_model2.add(tf.keras.layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "cnn_model2.add(tf.keras.layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "cnn_model2.add(tf.keras.layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "cnn_model2.add(tf.keras.layers.MaxPooling2D(\n",
    "    (2, 2), strides=(2, 2), padding='same'))\n",
    "cnn_model2.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# flatten output and feed it into dense layer\n",
    "cnn_model2.add(tf.keras.layers.Flatten())\n",
    "cnn_model2.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "cnn_model2.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "cnn_model2.add(tf.keras.layers.Dense(6, activation='softmax'))\n",
    "optimiser = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "cnn_model2.summary()\n",
    "cnn_model2.compile(optimizer=optimiser,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "cnn_history2 = cnn_model2.fit(train_data_value, train_data_target, validation_data=(\n",
    "    test_data_value, test_data_target), batch_size=32, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_11 (Conv2D)          (None, 154, 38, 128)      1280      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 77, 19, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 77, 19, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 75, 17, 64)        73792     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 38, 9, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 38, 9, 64)        256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 21888)             0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                1400896   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,477,126\n",
      "Trainable params: 1,476,742\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "187/187 [==============================] - 7s 33ms/step - loss: 1.6839 - accuracy: 0.2857 - val_loss: 1.5582 - val_accuracy: 0.3633\n",
      "Epoch 2/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 1.5341 - accuracy: 0.3539 - val_loss: 1.4664 - val_accuracy: 0.4124\n",
      "Epoch 3/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 1.4602 - accuracy: 0.3865 - val_loss: 1.3645 - val_accuracy: 0.4540\n",
      "Epoch 4/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 1.3856 - accuracy: 0.4213 - val_loss: 1.4747 - val_accuracy: 0.4231\n",
      "Epoch 5/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 1.3335 - accuracy: 0.4599 - val_loss: 1.3342 - val_accuracy: 0.4835\n",
      "Epoch 6/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 1.2614 - accuracy: 0.4843 - val_loss: 1.3053 - val_accuracy: 0.4929\n",
      "Epoch 7/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 1.1905 - accuracy: 0.5248 - val_loss: 1.2977 - val_accuracy: 0.4976\n",
      "Epoch 8/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 1.1312 - accuracy: 0.5498 - val_loss: 1.2767 - val_accuracy: 0.4835\n",
      "Epoch 9/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 1.0774 - accuracy: 0.5686 - val_loss: 1.2375 - val_accuracy: 0.5272\n",
      "Epoch 10/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 0.9811 - accuracy: 0.6152 - val_loss: 1.2700 - val_accuracy: 0.5071\n",
      "Epoch 11/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 0.9205 - accuracy: 0.6385 - val_loss: 1.2560 - val_accuracy: 0.5259\n",
      "Epoch 12/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 0.8286 - accuracy: 0.6823 - val_loss: 1.2509 - val_accuracy: 0.5212\n",
      "Epoch 13/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 0.7684 - accuracy: 0.7022 - val_loss: 1.2274 - val_accuracy: 0.5534\n",
      "Epoch 14/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 0.7064 - accuracy: 0.7302 - val_loss: 1.2675 - val_accuracy: 0.5306\n",
      "Epoch 15/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 0.6626 - accuracy: 0.7469 - val_loss: 1.2825 - val_accuracy: 0.5299\n",
      "Epoch 16/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 0.5833 - accuracy: 0.7776 - val_loss: 1.2697 - val_accuracy: 0.5413\n",
      "Epoch 17/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 0.5134 - accuracy: 0.8145 - val_loss: 1.2877 - val_accuracy: 0.5346\n",
      "Epoch 18/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 0.5227 - accuracy: 0.8080 - val_loss: 1.3608 - val_accuracy: 0.5339\n",
      "Epoch 19/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 0.4981 - accuracy: 0.8181 - val_loss: 1.4442 - val_accuracy: 0.5205\n",
      "Epoch 20/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 0.3849 - accuracy: 0.8670 - val_loss: 1.3508 - val_accuracy: 0.5601\n"
     ]
    }
   ],
   "source": [
    "cnn_model3 = tf.keras.Sequential()\n",
    "cnn_model3.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=(\n",
    "    train_data_value.shape[1], train_data_value.shape[2], 1)))\n",
    "cnn_model3.add(tf.keras.layers.MaxPooling2D(\n",
    "    (3, 3), strides=(2, 2), padding='same'))\n",
    "cnn_model3.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# 2nd conv layer\n",
    "cnn_model3.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn_model3.add(tf.keras.layers.MaxPooling2D(\n",
    "    (3, 3), strides=(2, 2), padding='same'))\n",
    "cnn_model3.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# flatten output and feed it into dense layer\n",
    "cnn_model3.add(tf.keras.layers.Flatten())\n",
    "cnn_model3.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "cnn_model3.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "cnn_model3.add(tf.keras.layers.Dense(6, activation='softmax'))\n",
    "optimiser = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "cnn_model3.summary()\n",
    "cnn_model3.compile(optimizer=optimiser,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "cnn_history3 = cnn_model3.fit(train_data_value, train_data_target, validation_data=(\n",
    "    test_data_value, test_data_target), batch_size=32, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_weighted_model = tf.keras.applications.resnet50.ResNet50(\n",
    "    include_top=False, weights='imagenet', input_shape=(train_data_value.shape[1], train_data_value.shape[2], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...    0    0    0]\n",
      " [   0    0    0 ...    0    0    0]\n",
      " [   0    0    0 ...    0    0    0]\n",
      " ...\n",
      " [-453  113   30 ...   -5   -2   -4]\n",
      " [-456  114   36 ...   -6   -4   -7]\n",
      " [-462  117   34 ...   -4   -2   -4]]\n"
     ]
    }
   ],
   "source": [
    "print(train_data_value[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5953, 156, 40)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_value_reshaped2 = np.zeros((5953, 156, 40, 3))\n",
    "train_data_value_reshaped2[..., 0] = train_data_value\n",
    "train_data_value_reshaped2[..., 1] = train_data_value\n",
    "train_data_value_reshaped2[..., 2] = train_data_value\n",
    "test_data_value_reshaped2 = np.zeros((test_data_value.shape[0], 156, 40, 3))\n",
    "test_data_value_reshaped2[..., 0] = test_data_value\n",
    "test_data_value_reshaped2[..., 1] = test_data_value\n",
    "test_data_value_reshaped2[..., 2] = test_data_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_value_reshaped = np.repeat(train_data_value, 3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_value_reshaped = np.repeat(test_data_value, 3, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5953, 156, 40)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 5, 2, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 20480)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              20972544  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 6150      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,566,406\n",
      "Trainable params: 20,978,694\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_model_imagenet = tf.keras.Sequential()\n",
    "for layer in base_weighted_model.layers:\n",
    "    layer.trainable = False\n",
    "resnet_model_imagenet.add(base_weighted_model)\n",
    "resnet_model_imagenet.add(tf.keras.layers.Flatten())\n",
    "resnet_model_imagenet.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "resnet_model_imagenet.add(tf.keras.layers.Dropout(0.3))\n",
    "resnet_model_imagenet.add(tf.keras.layers.Dense(6, activation=\"softmax\"))\n",
    "resnet_model_imagenet.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "94/94 [==============================] - 15s 102ms/step - loss: 2.3183 - accuracy: 0.3775 - val_loss: 1.4482 - val_accuracy: 0.4157\n",
      "Epoch 2/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 1.3533 - accuracy: 0.4621 - val_loss: 1.4310 - val_accuracy: 0.3909\n",
      "Epoch 3/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 1.2731 - accuracy: 0.5058 - val_loss: 1.3051 - val_accuracy: 0.4829\n",
      "Epoch 4/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 1.2472 - accuracy: 0.4991 - val_loss: 1.2745 - val_accuracy: 0.4889\n",
      "Epoch 5/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 1.1696 - accuracy: 0.5392 - val_loss: 1.2726 - val_accuracy: 0.5104\n",
      "Epoch 6/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 1.1458 - accuracy: 0.5503 - val_loss: 1.2698 - val_accuracy: 0.5044\n",
      "Epoch 7/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 1.0988 - accuracy: 0.5737 - val_loss: 1.2778 - val_accuracy: 0.4923\n",
      "Epoch 8/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 1.0696 - accuracy: 0.5800 - val_loss: 1.3001 - val_accuracy: 0.5003\n",
      "Epoch 9/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 1.0985 - accuracy: 0.5668 - val_loss: 1.3337 - val_accuracy: 0.4674\n",
      "Epoch 10/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 1.0422 - accuracy: 0.5975 - val_loss: 1.3290 - val_accuracy: 0.4849\n",
      "Epoch 11/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 0.9785 - accuracy: 0.6217 - val_loss: 1.3413 - val_accuracy: 0.5064\n",
      "Epoch 12/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.9594 - accuracy: 0.6321 - val_loss: 1.3860 - val_accuracy: 0.4849\n",
      "Epoch 13/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.8935 - accuracy: 0.6509 - val_loss: 1.3507 - val_accuracy: 0.4896\n",
      "Epoch 14/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.8423 - accuracy: 0.6785 - val_loss: 1.3295 - val_accuracy: 0.5084\n",
      "Epoch 15/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 0.8093 - accuracy: 0.6855 - val_loss: 1.3377 - val_accuracy: 0.4950\n",
      "Epoch 16/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 0.8418 - accuracy: 0.6825 - val_loss: 1.3946 - val_accuracy: 0.4782\n",
      "Epoch 17/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.7686 - accuracy: 0.7030 - val_loss: 1.3671 - val_accuracy: 0.4970\n",
      "Epoch 18/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.7360 - accuracy: 0.7215 - val_loss: 1.5491 - val_accuracy: 0.4560\n",
      "Epoch 19/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.8241 - accuracy: 0.6808 - val_loss: 1.5254 - val_accuracy: 0.4728\n",
      "Epoch 20/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 0.8245 - accuracy: 0.6790 - val_loss: 1.5375 - val_accuracy: 0.4701\n",
      "Epoch 21/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.8119 - accuracy: 0.6881 - val_loss: 1.4038 - val_accuracy: 0.4936\n",
      "Epoch 22/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.7624 - accuracy: 0.7013 - val_loss: 1.7471 - val_accuracy: 0.4171\n",
      "Epoch 23/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 0.8748 - accuracy: 0.6654 - val_loss: 1.4470 - val_accuracy: 0.4822\n",
      "Epoch 24/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.8536 - accuracy: 0.6666 - val_loss: 1.3578 - val_accuracy: 0.4795\n",
      "Epoch 25/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.8249 - accuracy: 0.6744 - val_loss: 1.4128 - val_accuracy: 0.4882\n",
      "Epoch 26/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.8210 - accuracy: 0.6783 - val_loss: 1.4262 - val_accuracy: 0.4903\n",
      "Epoch 27/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.8230 - accuracy: 0.6758 - val_loss: 1.3825 - val_accuracy: 0.5003\n",
      "Epoch 28/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.6900 - accuracy: 0.7230 - val_loss: 1.5513 - val_accuracy: 0.4936\n",
      "Epoch 29/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.7157 - accuracy: 0.7153 - val_loss: 1.4687 - val_accuracy: 0.4842\n",
      "Epoch 30/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.6679 - accuracy: 0.7324 - val_loss: 1.6002 - val_accuracy: 0.4956\n",
      "Epoch 31/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.6096 - accuracy: 0.7615 - val_loss: 1.5969 - val_accuracy: 0.5044\n",
      "Epoch 32/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.5898 - accuracy: 0.7635 - val_loss: 1.7220 - val_accuracy: 0.4889\n",
      "Epoch 33/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.6522 - accuracy: 0.7354 - val_loss: 1.6521 - val_accuracy: 0.4943\n",
      "Epoch 34/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.6062 - accuracy: 0.7638 - val_loss: 1.5729 - val_accuracy: 0.4782\n",
      "Epoch 35/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 0.6253 - accuracy: 0.7519 - val_loss: 1.6573 - val_accuracy: 0.4950\n",
      "Epoch 36/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.5969 - accuracy: 0.7687 - val_loss: 1.8118 - val_accuracy: 0.4735\n",
      "Epoch 37/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 0.6403 - accuracy: 0.7432 - val_loss: 1.6466 - val_accuracy: 0.4842\n",
      "Epoch 38/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.5889 - accuracy: 0.7684 - val_loss: 1.6925 - val_accuracy: 0.4822\n",
      "Epoch 39/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.5458 - accuracy: 0.7816 - val_loss: 1.8070 - val_accuracy: 0.4916\n",
      "Epoch 40/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.6034 - accuracy: 0.7611 - val_loss: 1.6542 - val_accuracy: 0.5044\n",
      "Epoch 41/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.5272 - accuracy: 0.7858 - val_loss: 1.6561 - val_accuracy: 0.4815\n",
      "Epoch 42/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.5374 - accuracy: 0.7811 - val_loss: 1.8359 - val_accuracy: 0.4755\n",
      "Epoch 43/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 0.5891 - accuracy: 0.7620 - val_loss: 1.7046 - val_accuracy: 0.4762\n",
      "Epoch 44/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.5228 - accuracy: 0.7885 - val_loss: 2.0302 - val_accuracy: 0.4647\n",
      "Epoch 45/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 0.6489 - accuracy: 0.7390 - val_loss: 1.8517 - val_accuracy: 0.4312\n",
      "Epoch 46/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.7141 - accuracy: 0.7159 - val_loss: 1.7598 - val_accuracy: 0.4788\n",
      "Epoch 47/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.7170 - accuracy: 0.7069 - val_loss: 1.7187 - val_accuracy: 0.4842\n",
      "Epoch 48/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.7038 - accuracy: 0.7153 - val_loss: 1.6460 - val_accuracy: 0.4835\n",
      "Epoch 49/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.6088 - accuracy: 0.7549 - val_loss: 1.7763 - val_accuracy: 0.4815\n",
      "Epoch 50/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.5947 - accuracy: 0.7598 - val_loss: 1.8000 - val_accuracy: 0.4795\n"
     ]
    }
   ],
   "source": [
    "optimiser = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "resnet_model_imagenet.compile(optimizer=optimiser,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "resnet_history_weighted = resnet_model_imagenet.fit(train_data_value_reshaped2, train_data_target, validation_data=(\n",
    "    test_data_value_reshaped2, test_data_target), batch_size=64, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 2s 46ms/step - loss: 1.8000 - accuracy: 0.4795\n",
      "1.7999998331069946\n",
      "0.4795164465904236\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Expected dimension in the range [0, 0), but got 1 [Op:ArgMax]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(test_acc)\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m x,y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(test_data_value_reshaped2, test_data_target):\n\u001b[1;32m----> 9\u001b[0m     y_true\u001b[39m.\u001b[39mextend(tf\u001b[39m.\u001b[39;49margmax(y, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[0;32m     10\u001b[0m     y_pred\u001b[39m.\u001b[39mextend(tf\u001b[39m.\u001b[39margmax(resnet_model_imagenet\u001b[39m.\u001b[39mpredict(x), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m     11\u001b[0m \u001b[39m# for x, y in test_data_value_reshaped2:\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m#     y_true.extend(tf.argmax(y, axis=1))\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m#     y_pred.extend(tf.argmax(resnet_model_imagenet.predict(x), axis=1))\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39m# print('Confusion Matrix:')\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m# print(cm)\u001b[39;00m\n",
      "File \u001b[1;32me:\\TA-Bill\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32me:\\TA-Bill\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Expected dimension in the range [0, 0), but got 1 [Op:ArgMax]"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = resnet_model_imagenet.evaluate(test_data_value_reshaped2, test_data_target)\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "print(test_loss)\n",
    "print(test_acc)\n",
    "\n",
    "for x,y in zip(test_data_value_reshaped2, test_data_target):\n",
    "    y_true.extend(tf.argmax(y))\n",
    "    y_pred.extend(tf.argmax(resnet_model_imagenet.predict(x)))\n",
    "\n",
    "    \n",
    "# for x, y in test_data_value_reshaped2:\n",
    "#     y_true.extend(tf.argmax(y, axis=1))\n",
    "#     y_pred.extend(tf.argmax(resnet_model_imagenet.predict(x), axis=1))\n",
    "\n",
    "# cm = tf.math.confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# print('Confusion Matrix:')\n",
    "# print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the ELU and ReLU activation functions\n",
    "def elu(x, alpha=1.0):\n",
    "    return np.where(x >= 0, x, alpha * (np.exp(x) - 1))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Generate some sample data\n",
    "x = np.linspace(-5, 5, 100)\n",
    "\n",
    "# Compute the output of the ELU and ReLU activation functions\n",
    "y_elu = elu(x)\n",
    "y_relu = relu(x)\n",
    "\n",
    "# Plot the results\n",
    "# plt.subplot(figsize=(4))\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "plt.plot(x, y_elu, label='ELU')\n",
    "plt.plot(x, y_relu, label='ReLU')\n",
    "plt.xlabel('Input')\n",
    "plt.ylabel('Output')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the ELU and ReLU activation functions\n",
    "def elu(x, alpha=1.0):\n",
    "    return np.where(x >= 0, x, alpha * (np.exp(x) - 1))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Generate some sample data\n",
    "x = np.linspace(-5, 5, 100)\n",
    "\n",
    "# Compute the output of the ELU and ReLU activation functions\n",
    "y_elu = elu(x)\n",
    "y_relu = elu(x, 0.7)\n",
    "\n",
    "# Plot the results\n",
    "# plt.subplot(figsize=(4))\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "plt.plot(x, y_elu, label='ELU')\n",
    "plt.plot(x, y_relu, label='ELU 0.7')\n",
    "plt.xlabel('Input')\n",
    "plt.ylabel('Output')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
