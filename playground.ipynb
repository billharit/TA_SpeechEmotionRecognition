{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from dataset import load_to_dataframe, turn_into_data_for_model, get_sample_rate\n",
    "from model import train_cnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size:0\n",
      "Train Size:300\n",
      "Train Size:600\n",
      "Train Size:900\n",
      "Train Size:1200\n",
      "Train Size:1500\n",
      "Train Size:1800\n",
      "Train Size:2100\n",
      "Train Size:2400\n",
      "Train Size:2700\n",
      "Train Size:3000\n",
      "Train Size:3300\n",
      "Train Size:3600\n",
      "Train Size:3900\n",
      "Train Size:4200\n",
      "Train Size:4500\n",
      "Train Size:4800\n",
      "Train Size:5100\n",
      "Train Size:5400\n",
      "Train Size:5700\n",
      "Test Size:0\n",
      "Test Size:300\n",
      "Test Size:600\n",
      "Test Size:900\n",
      "Test Size:1200\n",
      "(5953, 156, 40)\n",
      "(1489, 156, 40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\TA-Bill\\dataset.py:139: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_data_value = np.asarray(train_data['mfcc'])\n",
      "E:\\TA-Bill\\dataset.py:143: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  test_data_value = np.asarray(test_data['mfcc'])\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = load_to_dataframe('dataset/train', 'dataset/test')\n",
    "train_data_value, train_data_target, test_data_value, test_data_target = turn_into_data_for_model(\n",
    "    train_df, test_df, 40, 2048, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"40_2048_512_train_data_value\", train_data_value)\n",
    "# np.save(\"40_2048_512_train_data_target\", train_data_target)\n",
    "# np.save(\"40_2048_512_test_data_value\", test_data_value)\n",
    "# np.save(\"40_2048_512_test_data_target\", test_data_target)\n",
    "\n",
    "train_data_value = np.load('40_2048_512_train_data_value.npy')\n",
    "train_data_target = np.load('40_2048_512_train_data_target.npy')\n",
    "test_data_value = np.load('40_2048_512_test_data_value.npy')\n",
    "test_data_target = np.load('40_2048_512_test_data_target.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 5, 2, 2048)        23581440  \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 20480)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1024)              20972544  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 6)                 6150      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,560,134\n",
      "Trainable params: 44,507,014\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_model = tf.keras.Sequential()\n",
    "base_model = tf.keras.applications.resnet50.ResNet50(\n",
    "    include_top=False, weights=None, input_shape=(train_data_value.shape[1], train_data_value.shape[2], 1))\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "resnet_model.add(base_model)\n",
    "resnet_model.add(tf.keras.layers.Flatten())\n",
    "resnet_model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "resnet_model.add(tf.keras.layers.Dropout(0.3))\n",
    "resnet_model.add(tf.keras.layers.Dense(6, activation=\"softmax\"))\n",
    "resnet_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "resnet_model.compile(optimizer=optimiser,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "187/187 [==============================] - 37s 163ms/step - loss: 5.8938 - accuracy: 0.2795 - val_loss: 1.6016 - val_accuracy: 0.2995\n",
      "Epoch 2/20\n",
      "187/187 [==============================] - 29s 158ms/step - loss: 1.5474 - accuracy: 0.3501 - val_loss: 1.6009 - val_accuracy: 0.3277\n",
      "Epoch 3/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.5194 - accuracy: 0.3854 - val_loss: 1.5238 - val_accuracy: 0.3694\n",
      "Epoch 4/20\n",
      "187/187 [==============================] - 30s 159ms/step - loss: 1.4555 - accuracy: 0.4208 - val_loss: 1.4238 - val_accuracy: 0.4171\n",
      "Epoch 5/20\n",
      "187/187 [==============================] - 30s 158ms/step - loss: 1.4520 - accuracy: 0.4173 - val_loss: 1.4145 - val_accuracy: 0.4540\n",
      "Epoch 6/20\n",
      "187/187 [==============================] - 30s 159ms/step - loss: 1.4348 - accuracy: 0.4292 - val_loss: 1.6656 - val_accuracy: 0.3224\n",
      "Epoch 7/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.3824 - accuracy: 0.4571 - val_loss: 1.3151 - val_accuracy: 0.4889\n",
      "Epoch 8/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.3090 - accuracy: 0.4959 - val_loss: 1.2625 - val_accuracy: 0.4909\n",
      "Epoch 9/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.3023 - accuracy: 0.4955 - val_loss: 1.7303 - val_accuracy: 0.2565\n",
      "Epoch 10/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.4903 - accuracy: 0.4153 - val_loss: 2.1136 - val_accuracy: 0.2337\n",
      "Epoch 11/20\n",
      "187/187 [==============================] - 30s 159ms/step - loss: 1.3433 - accuracy: 0.4816 - val_loss: 1.4016 - val_accuracy: 0.4513\n",
      "Epoch 12/20\n",
      "187/187 [==============================] - 30s 159ms/step - loss: 1.2943 - accuracy: 0.5053 - val_loss: 1.3374 - val_accuracy: 0.4882\n",
      "Epoch 13/20\n",
      "187/187 [==============================] - 29s 156ms/step - loss: 1.2420 - accuracy: 0.5212 - val_loss: 2.1253 - val_accuracy: 0.3358\n",
      "Epoch 14/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.3140 - accuracy: 0.4992 - val_loss: 2.0596 - val_accuracy: 0.3002\n",
      "Epoch 15/20\n",
      "187/187 [==============================] - 30s 158ms/step - loss: 1.4743 - accuracy: 0.4111 - val_loss: 1.6350 - val_accuracy: 0.3573\n",
      "Epoch 16/20\n",
      "187/187 [==============================] - 29s 158ms/step - loss: 1.3438 - accuracy: 0.4727 - val_loss: 1.3785 - val_accuracy: 0.4654\n",
      "Epoch 17/20\n",
      "187/187 [==============================] - 30s 158ms/step - loss: 1.3469 - accuracy: 0.4796 - val_loss: 2.8094 - val_accuracy: 0.1934\n",
      "Epoch 18/20\n",
      "187/187 [==============================] - 30s 159ms/step - loss: 1.3296 - accuracy: 0.4989 - val_loss: 1.7028 - val_accuracy: 0.3049\n",
      "Epoch 19/20\n",
      "187/187 [==============================] - 29s 158ms/step - loss: 1.4707 - accuracy: 0.4181 - val_loss: 1.2942 - val_accuracy: 0.4990\n",
      "Epoch 20/20\n",
      "187/187 [==============================] - 30s 158ms/step - loss: 1.3208 - accuracy: 0.4735 - val_loss: 1.5391 - val_accuracy: 0.3781\n"
     ]
    }
   ],
   "source": [
    "resnet_history = resnet_model.fit(train_data_value, train_data_target, validation_data=(\n",
    "    test_data_value, test_data_target), batch_size=32, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "187/187 [==============================] - 29s 156ms/step - loss: 1.2603 - accuracy: 0.4979 - val_loss: 1.5322 - val_accuracy: 0.4238\n",
      "Epoch 2/20\n",
      "187/187 [==============================] - 29s 156ms/step - loss: 1.2283 - accuracy: 0.5130 - val_loss: 1.3211 - val_accuracy: 0.4681\n",
      "Epoch 3/20\n",
      "187/187 [==============================] - 29s 156ms/step - loss: 1.2303 - accuracy: 0.5139 - val_loss: 2.9873 - val_accuracy: 0.3741\n",
      "Epoch 4/20\n",
      "187/187 [==============================] - 29s 156ms/step - loss: 1.2337 - accuracy: 0.5186 - val_loss: 1.3687 - val_accuracy: 0.4708\n",
      "Epoch 5/20\n",
      "187/187 [==============================] - 29s 156ms/step - loss: 1.2613 - accuracy: 0.5083 - val_loss: 1.6462 - val_accuracy: 0.3674\n",
      "Epoch 6/20\n",
      "187/187 [==============================] - 29s 156ms/step - loss: 1.3106 - accuracy: 0.4866 - val_loss: 1.9762 - val_accuracy: 0.1719\n",
      "Epoch 7/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.4312 - accuracy: 0.4292 - val_loss: 1.8307 - val_accuracy: 0.3257\n",
      "Epoch 8/20\n",
      "187/187 [==============================] - 30s 158ms/step - loss: 1.3721 - accuracy: 0.4616 - val_loss: 3.3499 - val_accuracy: 0.1854\n",
      "Epoch 9/20\n",
      "187/187 [==============================] - 30s 158ms/step - loss: 1.2751 - accuracy: 0.4996 - val_loss: 1.4116 - val_accuracy: 0.4453\n",
      "Epoch 10/20\n",
      "187/187 [==============================] - 30s 158ms/step - loss: 1.2858 - accuracy: 0.5031 - val_loss: 1.8014 - val_accuracy: 0.1713\n",
      "Epoch 11/20\n",
      "187/187 [==============================] - 30s 158ms/step - loss: 1.3721 - accuracy: 0.4515 - val_loss: 1.8005 - val_accuracy: 0.3264\n",
      "Epoch 12/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.3691 - accuracy: 0.4494 - val_loss: 1.4773 - val_accuracy: 0.4083\n",
      "Epoch 13/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.3274 - accuracy: 0.4662 - val_loss: 1.3357 - val_accuracy: 0.4500\n",
      "Epoch 14/20\n",
      "187/187 [==============================] - 29s 156ms/step - loss: 1.3964 - accuracy: 0.4394 - val_loss: 1.5595 - val_accuracy: 0.3546\n",
      "Epoch 15/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.2813 - accuracy: 0.4969 - val_loss: 2.0572 - val_accuracy: 0.3539\n",
      "Epoch 16/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.2306 - accuracy: 0.5296 - val_loss: 1.2607 - val_accuracy: 0.5024\n",
      "Epoch 17/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.3239 - accuracy: 0.4900 - val_loss: 1.7283 - val_accuracy: 0.3049\n",
      "Epoch 18/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.2176 - accuracy: 0.5201 - val_loss: 1.4068 - val_accuracy: 0.4291\n",
      "Epoch 19/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.1783 - accuracy: 0.5391 - val_loss: 1.2814 - val_accuracy: 0.4681\n",
      "Epoch 20/20\n",
      "187/187 [==============================] - 29s 157ms/step - loss: 1.2139 - accuracy: 0.5243 - val_loss: 2.2799 - val_accuracy: 0.3056\n"
     ]
    }
   ],
   "source": [
    "resnet_history = resnet_model.fit(train_data_value, train_data_target, validation_data=(\n",
    "    test_data_value, test_data_target), batch_size=64, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "resnet_model.compile(optimizer=optimiser,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "187/187 [==============================] - 16s 66ms/step - loss: 1.7902 - accuracy: 0.1700 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 2/20\n",
      "187/187 [==============================] - 11s 60ms/step - loss: 1.7902 - accuracy: 0.1643 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 3/20\n",
      "187/187 [==============================] - 11s 59ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 4/20\n",
      "187/187 [==============================] - 11s 57ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 5/20\n",
      "187/187 [==============================] - 11s 59ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 6/20\n",
      "187/187 [==============================] - 11s 59ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 7/20\n",
      "187/187 [==============================] - 11s 59ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 8/20\n",
      "187/187 [==============================] - 12s 62ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 9/20\n",
      "187/187 [==============================] - 11s 61ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 10/20\n",
      "187/187 [==============================] - 11s 60ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 11/20\n",
      "187/187 [==============================] - 11s 60ms/step - loss: 1.7902 - accuracy: 0.1697 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 12/20\n",
      "187/187 [==============================] - 11s 60ms/step - loss: 1.7902 - accuracy: 0.1690 - val_loss: 1.7902 - val_accuracy: 0.1713\n",
      "Epoch 13/20\n",
      "187/187 [==============================] - 11s 60ms/step - loss: 1.7902 - accuracy: 0.1623 - val_loss: 1.7902 - val_accuracy: 0.1713\n",
      "Epoch 14/20\n",
      "187/187 [==============================] - 12s 64ms/step - loss: 1.7902 - accuracy: 0.1702 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 15/20\n",
      "187/187 [==============================] - 11s 60ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 16/20\n",
      "187/187 [==============================] - 11s 60ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 17/20\n",
      "187/187 [==============================] - 11s 60ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 18/20\n",
      "187/187 [==============================] - 11s 60ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 19/20\n",
      "187/187 [==============================] - 11s 60ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n",
      "Epoch 20/20\n",
      "187/187 [==============================] - 11s 59ms/step - loss: 1.7902 - accuracy: 0.1708 - val_loss: 1.7902 - val_accuracy: 0.1706\n"
     ]
    }
   ],
   "source": [
    "resnet_history2 = resnet_model.fit(train_data_value, train_data_target, validation_data=(\n",
    "    test_data_value, test_data_target), batch_size=32, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 154, 38, 128)      1280      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 77, 19, 128)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 77, 19, 128)      512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 75, 17, 64)        73792     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 38, 9, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 38, 9, 64)        256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 37, 8, 32)         8224      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 19, 4, 32)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 19, 4, 32)        128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2432)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                155712    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 240,294\n",
      "Trainable params: 239,846\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "187/187 [==============================] - 9s 36ms/step - loss: 1.7193 - accuracy: 0.2936 - val_loss: 1.4846 - val_accuracy: 0.3895\n",
      "Epoch 2/20\n",
      "187/187 [==============================] - 6s 34ms/step - loss: 1.4957 - accuracy: 0.3736 - val_loss: 1.4057 - val_accuracy: 0.4070\n",
      "Epoch 3/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 1.4332 - accuracy: 0.4109 - val_loss: 1.3681 - val_accuracy: 0.4399\n",
      "Epoch 4/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 1.3689 - accuracy: 0.4460 - val_loss: 1.3300 - val_accuracy: 0.4634\n",
      "Epoch 5/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 1.3121 - accuracy: 0.4730 - val_loss: 1.3236 - val_accuracy: 0.4647\n",
      "Epoch 6/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 1.2605 - accuracy: 0.4991 - val_loss: 1.2730 - val_accuracy: 0.4849\n",
      "Epoch 7/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 1.2150 - accuracy: 0.5192 - val_loss: 1.2489 - val_accuracy: 0.5010\n",
      "Epoch 8/20\n",
      "187/187 [==============================] - 6s 35ms/step - loss: 1.1822 - accuracy: 0.5302 - val_loss: 1.2250 - val_accuracy: 0.5158\n",
      "Epoch 9/20\n",
      "187/187 [==============================] - 6s 34ms/step - loss: 1.1293 - accuracy: 0.5560 - val_loss: 1.2221 - val_accuracy: 0.5279\n",
      "Epoch 10/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 1.1296 - accuracy: 0.5543 - val_loss: 1.2569 - val_accuracy: 0.5017\n",
      "Epoch 11/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 1.0454 - accuracy: 0.5970 - val_loss: 1.2657 - val_accuracy: 0.4923\n",
      "Epoch 12/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 1.0171 - accuracy: 0.6101 - val_loss: 1.2266 - val_accuracy: 0.5259\n",
      "Epoch 13/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 0.9776 - accuracy: 0.6288 - val_loss: 1.1827 - val_accuracy: 0.5400\n",
      "Epoch 14/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 0.9577 - accuracy: 0.6341 - val_loss: 1.1684 - val_accuracy: 0.5447\n",
      "Epoch 15/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 0.8999 - accuracy: 0.6583 - val_loss: 1.1564 - val_accuracy: 0.5487\n",
      "Epoch 16/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 0.8634 - accuracy: 0.6726 - val_loss: 1.2032 - val_accuracy: 0.5480\n",
      "Epoch 17/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 0.8228 - accuracy: 0.6983 - val_loss: 1.1556 - val_accuracy: 0.5541\n",
      "Epoch 18/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 0.7879 - accuracy: 0.7096 - val_loss: 1.1893 - val_accuracy: 0.5581\n",
      "Epoch 19/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 0.7377 - accuracy: 0.7233 - val_loss: 1.1791 - val_accuracy: 0.5641\n",
      "Epoch 20/20\n",
      "187/187 [==============================] - 6s 33ms/step - loss: 0.7038 - accuracy: 0.7437 - val_loss: 1.1751 - val_accuracy: 0.5735\n"
     ]
    }
   ],
   "source": [
    "cnn_model = tf.keras.Sequential()\n",
    "cnn_model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=(\n",
    "    train_data_value.shape[1], train_data_value.shape[2], 1)))\n",
    "cnn_model.add(tf.keras.layers.MaxPooling2D(\n",
    "    (3, 3), strides=(2, 2), padding='same'))\n",
    "cnn_model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# 2nd conv layer\n",
    "cnn_model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn_model.add(tf.keras.layers.MaxPooling2D(\n",
    "    (3, 3), strides=(2, 2), padding='same'))\n",
    "cnn_model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# 3rd conv layer\n",
    "cnn_model.add(tf.keras.layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "cnn_model.add(tf.keras.layers.MaxPooling2D(\n",
    "    (2, 2), strides=(2, 2), padding='same'))\n",
    "cnn_model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# flatten output and feed it into dense layer\n",
    "cnn_model.add(tf.keras.layers.Flatten())\n",
    "cnn_model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "cnn_model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "cnn_model.add(tf.keras.layers.Dense(6, activation='softmax'))\n",
    "optimiser = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "cnn_model.summary()\n",
    "cnn_model.compile(optimizer=optimiser,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "history = cnn_model.fit(train_data_value, train_data_target, validation_data=(\n",
    "    test_data_value, test_data_target), batch_size=32, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 154, 38, 128)      1280      \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 152, 36, 128)      147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 76, 18, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 76, 18, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 74, 16, 64)        73792     \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 72, 14, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 70, 12, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 35, 6, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 35, 6, 64)        256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 34, 5, 32)         8224      \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 33, 4, 32)         4128      \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 32, 3, 32)         4128      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 16, 2, 32)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 16, 2, 32)        128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                65600     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 379,878\n",
      "Trainable params: 379,430\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "187/187 [==============================] - 17s 83ms/step - loss: 1.8806 - accuracy: 0.2493 - val_loss: 1.6707 - val_accuracy: 0.2807\n",
      "Epoch 2/20\n",
      "187/187 [==============================] - 14s 74ms/step - loss: 1.6171 - accuracy: 0.3375 - val_loss: 1.5491 - val_accuracy: 0.3694\n",
      "Epoch 3/20\n",
      "187/187 [==============================] - 14s 72ms/step - loss: 1.5307 - accuracy: 0.3738 - val_loss: 1.4770 - val_accuracy: 0.3956\n",
      "Epoch 4/20\n",
      "187/187 [==============================] - 14s 73ms/step - loss: 1.4633 - accuracy: 0.4055 - val_loss: 1.4084 - val_accuracy: 0.4251\n",
      "Epoch 5/20\n",
      "187/187 [==============================] - 14s 74ms/step - loss: 1.4151 - accuracy: 0.4262 - val_loss: 1.3938 - val_accuracy: 0.4426\n",
      "Epoch 6/20\n",
      "187/187 [==============================] - 14s 74ms/step - loss: 1.3592 - accuracy: 0.4536 - val_loss: 1.3308 - val_accuracy: 0.4681\n",
      "Epoch 7/20\n",
      "187/187 [==============================] - 14s 74ms/step - loss: 1.2960 - accuracy: 0.4784 - val_loss: 1.3077 - val_accuracy: 0.4762\n",
      "Epoch 8/20\n",
      "187/187 [==============================] - 14s 74ms/step - loss: 1.2627 - accuracy: 0.5048 - val_loss: 1.3324 - val_accuracy: 0.4788\n",
      "Epoch 9/20\n",
      "187/187 [==============================] - 14s 74ms/step - loss: 1.2179 - accuracy: 0.5270 - val_loss: 1.2489 - val_accuracy: 0.5097\n",
      "Epoch 10/20\n",
      "187/187 [==============================] - 14s 74ms/step - loss: 1.2034 - accuracy: 0.5254 - val_loss: 1.2514 - val_accuracy: 0.4943\n",
      "Epoch 11/20\n",
      "187/187 [==============================] - 14s 73ms/step - loss: 1.1569 - accuracy: 0.5513 - val_loss: 1.3698 - val_accuracy: 0.4614\n",
      "Epoch 12/20\n",
      "187/187 [==============================] - 14s 74ms/step - loss: 1.1089 - accuracy: 0.5701 - val_loss: 1.3010 - val_accuracy: 0.4668\n",
      "Epoch 13/20\n",
      "187/187 [==============================] - 14s 73ms/step - loss: 1.0869 - accuracy: 0.5775 - val_loss: 1.1941 - val_accuracy: 0.5299\n",
      "Epoch 14/20\n",
      "187/187 [==============================] - 14s 74ms/step - loss: 1.0600 - accuracy: 0.5868 - val_loss: 1.2328 - val_accuracy: 0.5131\n",
      "Epoch 15/20\n",
      "187/187 [==============================] - 14s 74ms/step - loss: 1.0906 - accuracy: 0.5814 - val_loss: 1.2258 - val_accuracy: 0.5245\n",
      "Epoch 16/20\n",
      "187/187 [==============================] - 14s 75ms/step - loss: 1.0213 - accuracy: 0.6052 - val_loss: 1.2204 - val_accuracy: 0.5252\n",
      "Epoch 17/20\n",
      "187/187 [==============================] - 14s 75ms/step - loss: 0.9469 - accuracy: 0.6286 - val_loss: 1.3283 - val_accuracy: 0.4835\n",
      "Epoch 18/20\n",
      "187/187 [==============================] - 14s 74ms/step - loss: 0.9017 - accuracy: 0.6546 - val_loss: 1.1951 - val_accuracy: 0.5252\n",
      "Epoch 19/20\n",
      "187/187 [==============================] - 14s 74ms/step - loss: 0.9248 - accuracy: 0.6494 - val_loss: 1.2148 - val_accuracy: 0.5252\n",
      "Epoch 20/20\n",
      "187/187 [==============================] - 14s 74ms/step - loss: 0.9066 - accuracy: 0.6556 - val_loss: 1.1798 - val_accuracy: 0.5473\n"
     ]
    }
   ],
   "source": [
    "cnn_model2 = tf.keras.Sequential()\n",
    "cnn_model2.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=(\n",
    "    train_data_value.shape[1], train_data_value.shape[2], 1)))\n",
    "cnn_model2.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "cnn_model2.add(tf.keras.layers.MaxPooling2D(\n",
    "    (3, 3), strides=(2, 2), padding='same'))\n",
    "cnn_model2.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# 2nd conv layer\n",
    "cnn_model2.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn_model2.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn_model2.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn_model2.add(tf.keras.layers.MaxPooling2D(\n",
    "    (3, 3), strides=(2, 2), padding='same'))\n",
    "cnn_model2.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# 3rd conv layer\n",
    "cnn_model2.add(tf.keras.layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "cnn_model2.add(tf.keras.layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "cnn_model2.add(tf.keras.layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "cnn_model2.add(tf.keras.layers.MaxPooling2D(\n",
    "    (2, 2), strides=(2, 2), padding='same'))\n",
    "cnn_model2.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# flatten output and feed it into dense layer\n",
    "cnn_model2.add(tf.keras.layers.Flatten())\n",
    "cnn_model2.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "cnn_model2.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "cnn_model2.add(tf.keras.layers.Dense(6, activation='softmax'))\n",
    "optimiser = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "cnn_model2.summary()\n",
    "cnn_model2.compile(optimizer=optimiser,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "cnn_history2 = cnn_model2.fit(train_data_value, train_data_target, validation_data=(\n",
    "    test_data_value, test_data_target), batch_size=32, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_11 (Conv2D)          (None, 154, 38, 128)      1280      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 77, 19, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 77, 19, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 75, 17, 64)        73792     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 38, 9, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 38, 9, 64)        256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 21888)             0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                1400896   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,477,126\n",
      "Trainable params: 1,476,742\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "187/187 [==============================] - 7s 33ms/step - loss: 1.6839 - accuracy: 0.2857 - val_loss: 1.5582 - val_accuracy: 0.3633\n",
      "Epoch 2/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 1.5341 - accuracy: 0.3539 - val_loss: 1.4664 - val_accuracy: 0.4124\n",
      "Epoch 3/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 1.4602 - accuracy: 0.3865 - val_loss: 1.3645 - val_accuracy: 0.4540\n",
      "Epoch 4/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 1.3856 - accuracy: 0.4213 - val_loss: 1.4747 - val_accuracy: 0.4231\n",
      "Epoch 5/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 1.3335 - accuracy: 0.4599 - val_loss: 1.3342 - val_accuracy: 0.4835\n",
      "Epoch 6/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 1.2614 - accuracy: 0.4843 - val_loss: 1.3053 - val_accuracy: 0.4929\n",
      "Epoch 7/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 1.1905 - accuracy: 0.5248 - val_loss: 1.2977 - val_accuracy: 0.4976\n",
      "Epoch 8/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 1.1312 - accuracy: 0.5498 - val_loss: 1.2767 - val_accuracy: 0.4835\n",
      "Epoch 9/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 1.0774 - accuracy: 0.5686 - val_loss: 1.2375 - val_accuracy: 0.5272\n",
      "Epoch 10/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 0.9811 - accuracy: 0.6152 - val_loss: 1.2700 - val_accuracy: 0.5071\n",
      "Epoch 11/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 0.9205 - accuracy: 0.6385 - val_loss: 1.2560 - val_accuracy: 0.5259\n",
      "Epoch 12/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 0.8286 - accuracy: 0.6823 - val_loss: 1.2509 - val_accuracy: 0.5212\n",
      "Epoch 13/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 0.7684 - accuracy: 0.7022 - val_loss: 1.2274 - val_accuracy: 0.5534\n",
      "Epoch 14/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 0.7064 - accuracy: 0.7302 - val_loss: 1.2675 - val_accuracy: 0.5306\n",
      "Epoch 15/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 0.6626 - accuracy: 0.7469 - val_loss: 1.2825 - val_accuracy: 0.5299\n",
      "Epoch 16/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 0.5833 - accuracy: 0.7776 - val_loss: 1.2697 - val_accuracy: 0.5413\n",
      "Epoch 17/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 0.5134 - accuracy: 0.8145 - val_loss: 1.2877 - val_accuracy: 0.5346\n",
      "Epoch 18/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 0.5227 - accuracy: 0.8080 - val_loss: 1.3608 - val_accuracy: 0.5339\n",
      "Epoch 19/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 0.4981 - accuracy: 0.8181 - val_loss: 1.4442 - val_accuracy: 0.5205\n",
      "Epoch 20/20\n",
      "187/187 [==============================] - 6s 32ms/step - loss: 0.3849 - accuracy: 0.8670 - val_loss: 1.3508 - val_accuracy: 0.5601\n"
     ]
    }
   ],
   "source": [
    "cnn_model3 = tf.keras.Sequential()\n",
    "cnn_model3.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=(\n",
    "    train_data_value.shape[1], train_data_value.shape[2], 1)))\n",
    "cnn_model3.add(tf.keras.layers.MaxPooling2D(\n",
    "    (3, 3), strides=(2, 2), padding='same'))\n",
    "cnn_model3.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# 2nd conv layer\n",
    "cnn_model3.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn_model3.add(tf.keras.layers.MaxPooling2D(\n",
    "    (3, 3), strides=(2, 2), padding='same'))\n",
    "cnn_model3.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# flatten output and feed it into dense layer\n",
    "cnn_model3.add(tf.keras.layers.Flatten())\n",
    "cnn_model3.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "cnn_model3.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "cnn_model3.add(tf.keras.layers.Dense(6, activation='softmax'))\n",
    "optimiser = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "cnn_model3.summary()\n",
    "cnn_model3.compile(optimizer=optimiser,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "cnn_history3 = cnn_model3.fit(train_data_value, train_data_target, validation_data=(\n",
    "    test_data_value, test_data_target), batch_size=32, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_weighted_model = tf.keras.applications.resnet50.ResNet50(\n",
    "    include_top=False, weights='imagenet', input_shape=(train_data_value.shape[1], train_data_value.shape[2], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...    0    0    0]\n",
      " [   0    0    0 ...    0    0    0]\n",
      " [   0    0    0 ...    0    0    0]\n",
      " ...\n",
      " [-453  113   30 ...   -5   -2   -4]\n",
      " [-456  114   36 ...   -6   -4   -7]\n",
      " [-462  117   34 ...   -4   -2   -4]]\n"
     ]
    }
   ],
   "source": [
    "print(train_data_value[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5953, 156, 40)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_value_reshaped2 = np.zeros((5953, 156, 40, 3))\n",
    "train_data_value_reshaped2[..., 0] = train_data_value\n",
    "train_data_value_reshaped2[..., 1] = train_data_value\n",
    "train_data_value_reshaped2[..., 2] = train_data_value\n",
    "test_data_value_reshaped2 = np.zeros((test_data_value.shape[0], 156, 40, 3))\n",
    "test_data_value_reshaped2[..., 0] = test_data_value\n",
    "test_data_value_reshaped2[..., 1] = test_data_value\n",
    "test_data_value_reshaped2[..., 2] = test_data_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_value_reshaped = np.repeat(train_data_value, 3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_value_reshaped = np.repeat(test_data_value, 3, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5953, 156, 40)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_model_imagenet = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 5, 2, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 20480)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              20972544  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 6150      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,566,406\n",
      "Trainable params: 20,978,694\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_model_imagenet = tf.keras.Sequential()\n",
    "for layer in base_weighted_model.layers:\n",
    "    layer.trainable = False\n",
    "resnet_model_imagenet.add(base_weighted_model)\n",
    "resnet_model_imagenet.add(tf.keras.layers.Flatten())\n",
    "resnet_model_imagenet.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "resnet_model_imagenet.add(tf.keras.layers.Dropout(0.3))\n",
    "resnet_model_imagenet.add(tf.keras.layers.Dense(6, activation=\"softmax\"))\n",
    "resnet_model_imagenet.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "94/94 [==============================] - 15s 102ms/step - loss: 2.3183 - accuracy: 0.3775 - val_loss: 1.4482 - val_accuracy: 0.4157\n",
      "Epoch 2/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 1.3533 - accuracy: 0.4621 - val_loss: 1.4310 - val_accuracy: 0.3909\n",
      "Epoch 3/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 1.2731 - accuracy: 0.5058 - val_loss: 1.3051 - val_accuracy: 0.4829\n",
      "Epoch 4/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 1.2472 - accuracy: 0.4991 - val_loss: 1.2745 - val_accuracy: 0.4889\n",
      "Epoch 5/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 1.1696 - accuracy: 0.5392 - val_loss: 1.2726 - val_accuracy: 0.5104\n",
      "Epoch 6/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 1.1458 - accuracy: 0.5503 - val_loss: 1.2698 - val_accuracy: 0.5044\n",
      "Epoch 7/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 1.0988 - accuracy: 0.5737 - val_loss: 1.2778 - val_accuracy: 0.4923\n",
      "Epoch 8/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 1.0696 - accuracy: 0.5800 - val_loss: 1.3001 - val_accuracy: 0.5003\n",
      "Epoch 9/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 1.0985 - accuracy: 0.5668 - val_loss: 1.3337 - val_accuracy: 0.4674\n",
      "Epoch 10/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 1.0422 - accuracy: 0.5975 - val_loss: 1.3290 - val_accuracy: 0.4849\n",
      "Epoch 11/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 0.9785 - accuracy: 0.6217 - val_loss: 1.3413 - val_accuracy: 0.5064\n",
      "Epoch 12/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.9594 - accuracy: 0.6321 - val_loss: 1.3860 - val_accuracy: 0.4849\n",
      "Epoch 13/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.8935 - accuracy: 0.6509 - val_loss: 1.3507 - val_accuracy: 0.4896\n",
      "Epoch 14/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.8423 - accuracy: 0.6785 - val_loss: 1.3295 - val_accuracy: 0.5084\n",
      "Epoch 15/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 0.8093 - accuracy: 0.6855 - val_loss: 1.3377 - val_accuracy: 0.4950\n",
      "Epoch 16/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 0.8418 - accuracy: 0.6825 - val_loss: 1.3946 - val_accuracy: 0.4782\n",
      "Epoch 17/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.7686 - accuracy: 0.7030 - val_loss: 1.3671 - val_accuracy: 0.4970\n",
      "Epoch 18/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.7360 - accuracy: 0.7215 - val_loss: 1.5491 - val_accuracy: 0.4560\n",
      "Epoch 19/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.8241 - accuracy: 0.6808 - val_loss: 1.5254 - val_accuracy: 0.4728\n",
      "Epoch 20/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 0.8245 - accuracy: 0.6790 - val_loss: 1.5375 - val_accuracy: 0.4701\n",
      "Epoch 21/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.8119 - accuracy: 0.6881 - val_loss: 1.4038 - val_accuracy: 0.4936\n",
      "Epoch 22/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.7624 - accuracy: 0.7013 - val_loss: 1.7471 - val_accuracy: 0.4171\n",
      "Epoch 23/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 0.8748 - accuracy: 0.6654 - val_loss: 1.4470 - val_accuracy: 0.4822\n",
      "Epoch 24/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.8536 - accuracy: 0.6666 - val_loss: 1.3578 - val_accuracy: 0.4795\n",
      "Epoch 25/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.8249 - accuracy: 0.6744 - val_loss: 1.4128 - val_accuracy: 0.4882\n",
      "Epoch 26/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.8210 - accuracy: 0.6783 - val_loss: 1.4262 - val_accuracy: 0.4903\n",
      "Epoch 27/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.8230 - accuracy: 0.6758 - val_loss: 1.3825 - val_accuracy: 0.5003\n",
      "Epoch 28/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.6900 - accuracy: 0.7230 - val_loss: 1.5513 - val_accuracy: 0.4936\n",
      "Epoch 29/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.7157 - accuracy: 0.7153 - val_loss: 1.4687 - val_accuracy: 0.4842\n",
      "Epoch 30/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.6679 - accuracy: 0.7324 - val_loss: 1.6002 - val_accuracy: 0.4956\n",
      "Epoch 31/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.6096 - accuracy: 0.7615 - val_loss: 1.5969 - val_accuracy: 0.5044\n",
      "Epoch 32/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.5898 - accuracy: 0.7635 - val_loss: 1.7220 - val_accuracy: 0.4889\n",
      "Epoch 33/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.6522 - accuracy: 0.7354 - val_loss: 1.6521 - val_accuracy: 0.4943\n",
      "Epoch 34/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.6062 - accuracy: 0.7638 - val_loss: 1.5729 - val_accuracy: 0.4782\n",
      "Epoch 35/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 0.6253 - accuracy: 0.7519 - val_loss: 1.6573 - val_accuracy: 0.4950\n",
      "Epoch 36/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.5969 - accuracy: 0.7687 - val_loss: 1.8118 - val_accuracy: 0.4735\n",
      "Epoch 37/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 0.6403 - accuracy: 0.7432 - val_loss: 1.6466 - val_accuracy: 0.4842\n",
      "Epoch 38/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.5889 - accuracy: 0.7684 - val_loss: 1.6925 - val_accuracy: 0.4822\n",
      "Epoch 39/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.5458 - accuracy: 0.7816 - val_loss: 1.8070 - val_accuracy: 0.4916\n",
      "Epoch 40/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.6034 - accuracy: 0.7611 - val_loss: 1.6542 - val_accuracy: 0.5044\n",
      "Epoch 41/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.5272 - accuracy: 0.7858 - val_loss: 1.6561 - val_accuracy: 0.4815\n",
      "Epoch 42/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.5374 - accuracy: 0.7811 - val_loss: 1.8359 - val_accuracy: 0.4755\n",
      "Epoch 43/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 0.5891 - accuracy: 0.7620 - val_loss: 1.7046 - val_accuracy: 0.4762\n",
      "Epoch 44/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.5228 - accuracy: 0.7885 - val_loss: 2.0302 - val_accuracy: 0.4647\n",
      "Epoch 45/50\n",
      "94/94 [==============================] - 8s 81ms/step - loss: 0.6489 - accuracy: 0.7390 - val_loss: 1.8517 - val_accuracy: 0.4312\n",
      "Epoch 46/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.7141 - accuracy: 0.7159 - val_loss: 1.7598 - val_accuracy: 0.4788\n",
      "Epoch 47/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.7170 - accuracy: 0.7069 - val_loss: 1.7187 - val_accuracy: 0.4842\n",
      "Epoch 48/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.7038 - accuracy: 0.7153 - val_loss: 1.6460 - val_accuracy: 0.4835\n",
      "Epoch 49/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.6088 - accuracy: 0.7549 - val_loss: 1.7763 - val_accuracy: 0.4815\n",
      "Epoch 50/50\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.5947 - accuracy: 0.7598 - val_loss: 1.8000 - val_accuracy: 0.4795\n"
     ]
    }
   ],
   "source": [
    "optimiser = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "resnet_model_imagenet.compile(optimizer=optimiser,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "resnet_history_weighted = resnet_model_imagenet.fit(train_data_value_reshaped2, train_data_target, validation_data=(\n",
    "    test_data_value_reshaped2, test_data_target), batch_size=64, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 2s 46ms/step - loss: 1.8000 - accuracy: 0.4795\n",
      "1.7999998331069946\n",
      "0.4795164465904236\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Expected dimension in the range [0, 0), but got 1 [Op:ArgMax]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(test_acc)\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m x,y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(test_data_value_reshaped2, test_data_target):\n\u001b[1;32m----> 9\u001b[0m     y_true\u001b[39m.\u001b[39mextend(tf\u001b[39m.\u001b[39;49margmax(y, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[0;32m     10\u001b[0m     y_pred\u001b[39m.\u001b[39mextend(tf\u001b[39m.\u001b[39margmax(resnet_model_imagenet\u001b[39m.\u001b[39mpredict(x), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m     11\u001b[0m \u001b[39m# for x, y in test_data_value_reshaped2:\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m#     y_true.extend(tf.argmax(y, axis=1))\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m#     y_pred.extend(tf.argmax(resnet_model_imagenet.predict(x), axis=1))\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39m# print('Confusion Matrix:')\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m# print(cm)\u001b[39;00m\n",
      "File \u001b[1;32me:\\TA-Bill\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32me:\\TA-Bill\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Expected dimension in the range [0, 0), but got 1 [Op:ArgMax]"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = resnet_model_imagenet.evaluate(test_data_value_reshaped2, test_data_target)\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "print(test_loss)\n",
    "print(test_acc)\n",
    "\n",
    "for x,y in zip(test_data_value_reshaped2, test_data_target):\n",
    "    y_true.extend(tf.argmax(y))\n",
    "    y_pred.extend(tf.argmax(resnet_model_imagenet.predict(x)))\n",
    "\n",
    "    \n",
    "# for x, y in test_data_value_reshaped2:\n",
    "#     y_true.extend(tf.argmax(y, axis=1))\n",
    "#     y_pred.extend(tf.argmax(resnet_model_imagenet.predict(x), axis=1))\n",
    "\n",
    "# cm = tf.math.confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# print('Confusion Matrix:')\n",
    "# print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
