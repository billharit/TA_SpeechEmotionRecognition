{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def load_to_dataframe(train_folder_path, test_folder_path):\n",
    "    \"\"\"\n",
    "    Loads train and test data from the specified file folders, and returns them as pandas DataFrame objects.\n",
    "    :param train_folder_path: The path to the folder containing the train data files.\n",
    "    :type train_folder_path: str\n",
    "    :param test_folder_path: The path to the folder containing the test data files.\n",
    "    :type test_folder_path: str\n",
    "    :return: A two pandas DataFrame objects, containing the train and test data, respectively.\n",
    "    :rtype: pandas.core.frame.DataFrame, pandas.core.frame.DataFrame\n",
    "    \"\"\"\n",
    "    train_path = 'dataset/train'\n",
    "    test_path = 'dataset/test'\n",
    "    train_dir_list = os.listdir(train_path)\n",
    "    test_dir_list = os.listdir(test_path)\n",
    "\n",
    "    train_sentiment_value = []\n",
    "    test_sentiment_value = []\n",
    "    train_file_path = []\n",
    "    test_file_path = []\n",
    "\n",
    "    for file in train_dir_list:\n",
    "        train_file_path.append(train_path + '/' + file)\n",
    "        sentiment_code = file.split('_')\n",
    "        if sentiment_code[2] == 'ANG':\n",
    "            train_sentiment_value.append('angry')\n",
    "        elif sentiment_code[2] == 'DIS':\n",
    "            train_sentiment_value.append('disgust')\n",
    "        elif sentiment_code[2] == 'FEA':\n",
    "            train_sentiment_value.append('fear')\n",
    "        elif sentiment_code[2] == 'HAP':\n",
    "            train_sentiment_value.append('happy')\n",
    "        elif sentiment_code[2] == 'NEU':\n",
    "            train_sentiment_value.append('neutral')\n",
    "        elif sentiment_code[2] == 'SAD':\n",
    "            train_sentiment_value.append('sad')\n",
    "        else:\n",
    "            train_sentiment_value.append('unknown')\n",
    "\n",
    "    for file in test_dir_list:\n",
    "        test_file_path.append(test_path + '/' + file)\n",
    "        sentiment_code = file.split('_')\n",
    "        if sentiment_code[2] == 'ANG':\n",
    "            test_sentiment_value.append('angry')\n",
    "        elif sentiment_code[2] == 'DIS':\n",
    "            test_sentiment_value.append('disgust')\n",
    "        elif sentiment_code[2] == 'FEA':\n",
    "            test_sentiment_value.append('fear')\n",
    "        elif sentiment_code[2] == 'HAP':\n",
    "            test_sentiment_value.append('happy')\n",
    "        elif sentiment_code[2] == 'NEU':\n",
    "            test_sentiment_value.append('neutral')\n",
    "        elif sentiment_code[2] == 'SAD':\n",
    "            test_sentiment_value.append('sad')\n",
    "        else:\n",
    "            test_sentiment_value.append('unknown')\n",
    "\n",
    "    train_sentiment_df = pd.DataFrame(\n",
    "        {\"File_Path\": train_file_path, \"Target\": train_sentiment_value})\n",
    "\n",
    "    test_sentiment_df = pd.DataFrame(\n",
    "        {\"File_Path\": test_file_path, \"Target\": test_sentiment_value})\n",
    "\n",
    "    return train_sentiment_df, test_sentiment_df\n",
    "\n",
    "def turn_into_data_for_model(train_df, test_df, mfcc_number=40, fft=2048, hop=512, AugmentType = \"\"):\n",
    "    # Set Variable for MFCC\n",
    "    num_mfcc = mfcc_number\n",
    "    SAMPLE_RATE = 16000\n",
    "    n_fft = fft\n",
    "    hop_length = hop\n",
    "\n",
    "    train_data = {\n",
    "        \"labels\": [],\n",
    "        \"mfcc\": []\n",
    "    }\n",
    "\n",
    "    test_data = {\n",
    "        \"labels\": [],\n",
    "        \"mfcc\": []\n",
    "    }\n",
    "\n",
    "    # Encode Categories\n",
    "    labels = {'disgust': 0, 'happy': 1, 'sad': 2,\n",
    "              'neutral': 3, 'fear': 4, 'angry': 5}\n",
    "    train_df_encoded = train_df.replace({'Target': labels}, inplace=False)\n",
    "    test_df_encoded = test_df.replace({'Target': labels}, inplace=False)\n",
    "\n",
    "    for item, row in train_df.iterrows():\n",
    "        train_data['labels'].append(train_df_encoded.iloc[item, 1])\n",
    "        signal, sample_rate = librosa.load(\n",
    "            train_df_encoded.iloc[item, 0], sr=SAMPLE_RATE)\n",
    "        mfcc = librosa.feature.mfcc(\n",
    "            y=signal, sr=SAMPLE_RATE, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "        mfcc = mfcc.T\n",
    "        train_data[\"mfcc\"].append(np.asarray(mfcc))\n",
    "\n",
    "        if AugmentType != '':\n",
    "            try:\n",
    "                newAugment = train_df_encoded.iloc[item, 0].replace(\"train\", \"Augmented/{}\".format(AugmentType))\n",
    "                signal, sample_rate = librosa.load(\n",
    "                    newAugment, sr=SAMPLE_RATE)\n",
    "                mfcc = librosa.feature.mfcc(\n",
    "                    y=signal, sr=SAMPLE_RATE, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "                mfcc = mfcc.T\n",
    "                train_data['labels'].append(train_df_encoded.iloc[item, 1])\n",
    "                train_data[\"mfcc\"].append(np.asarray(mfcc))\n",
    "            except:\n",
    "                print(newAugment + \"Not Found\")\n",
    "\n",
    "        if item % 300 == 0:\n",
    "            print(\"Train Size:\" + str(math.floor(item)))\n",
    "\n",
    "    # for item, row in test_df.iterrows():\n",
    "    #     test_data['labels'].append(test_df_encoded.iloc[item, 1])\n",
    "    #     signal, sample_rate = librosa.load(\n",
    "    #         test_df_encoded.iloc[item, 0], sr=SAMPLE_RATE)\n",
    "    #     mfcc = librosa.feature.mfcc(\n",
    "    #         y=signal, sr=SAMPLE_RATE, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    #     mfcc = mfcc.T\n",
    "    #     test_data[\"mfcc\"].append(np.asarray(mfcc))\n",
    "    #     if item % 300 == 0:\n",
    "    #         print(\"Test Size:\" + str(math.floor(item)))\n",
    "\n",
    "    train_data_value = np.asarray(train_data['mfcc'])\n",
    "    train_data_target = np.asarray(train_data[\"labels\"])\n",
    "    # train_data_value = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    #     train_data_value, maxlen=156)\n",
    "    # test_data_value = np.asarray(test_data['mfcc'])\n",
    "    # test_data_target = np.asarray(test_data[\"labels\"])\n",
    "    # test_data_value = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    #     test_data_value, maxlen=156)\n",
    "    print(train_data_value.shape)\n",
    "    # print(test_data_value.shape)\n",
    "\n",
    "    # return train_data_value, train_data_target, test_data_value, test_data_target\n",
    "    return train_data_value, train_data_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = load_to_dataframe('dataset/train', 'dataset/test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size:0\n",
      "Train Size:300\n",
      "Train Size:600\n",
      "Train Size:900\n",
      "Train Size:1200\n",
      "Train Size:1500\n",
      "Train Size:1800\n",
      "Train Size:2100\n",
      "Train Size:2400\n",
      "Train Size:2700\n",
      "Train Size:3000\n",
      "Train Size:3300\n",
      "Train Size:3600\n",
      "Train Size:3900\n",
      "Train Size:4200\n",
      "Train Size:4500\n",
      "Train Size:4800\n",
      "Train Size:5100\n",
      "Train Size:5400\n",
      "Train Size:5700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\TA-Bill\\venv\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/Augmented/AddGaussianNoise/1091_WSI_SAD_XX.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32me:\\TA-Bill\\venv\\lib\\site-packages\\librosa\\core\\audio.py:164\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 164\u001b[0m     y, sr_native \u001b[39m=\u001b[39m __soundfile_load(path, offset, duration, dtype)\n\u001b[0;32m    166\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m    167\u001b[0m     \u001b[39m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "File \u001b[1;32me:\\TA-Bill\\venv\\lib\\site-packages\\librosa\\core\\audio.py:195\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    194\u001b[0m     \u001b[39m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[1;32m--> 195\u001b[0m     context \u001b[39m=\u001b[39m sf\u001b[39m.\u001b[39;49mSoundFile(path)\n\u001b[0;32m    197\u001b[0m \u001b[39mwith\u001b[39;00m context \u001b[39mas\u001b[39;00m sf_desc:\n",
      "File \u001b[1;32me:\\TA-Bill\\venv\\lib\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info \u001b[39m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[39mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(file, mode_int, closefd)\n\u001b[0;32m    659\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mset\u001b[39m(mode)\u001b[39m.\u001b[39missuperset(\u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[39m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "File \u001b[1;32me:\\TA-Bill\\venv\\lib\\site-packages\\soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1215\u001b[0m     err \u001b[39m=\u001b[39m _snd\u001b[39m.\u001b[39msf_error(file_ptr)\n\u001b[1;32m-> 1216\u001b[0m     \u001b[39mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError opening \u001b[39m\u001b[39m{0!r}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname))\n\u001b[0;32m   1217\u001b[0m \u001b[39mif\u001b[39;00m mode_int \u001b[39m==\u001b[39m _snd\u001b[39m.\u001b[39mSFM_WRITE:\n\u001b[0;32m   1218\u001b[0m     \u001b[39m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m     \u001b[39m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m     \u001b[39m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[1;31mLibsndfileError\u001b[0m: Error opening 'dataset/Augmented/AddGaussianNoise/1091_WSI_SAD_XX.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m crema_train_gaussian_value, crema_train_gaussian_target \u001b[39m=\u001b[39m turn_into_data_for_model(\n\u001b[0;32m      2\u001b[0m     train_df, test_df, \u001b[39m40\u001b[39;49m, \u001b[39m2048\u001b[39;49m, \u001b[39m512\u001b[39;49m, AugmentType\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mAddGaussianNoise\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[8], line 100\u001b[0m, in \u001b[0;36mturn_into_data_for_model\u001b[1;34m(train_df, test_df, mfcc_number, fft, hop, AugmentType)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[39mif\u001b[39;00m AugmentType \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     99\u001b[0m     newAugment \u001b[39m=\u001b[39m train_df_encoded\u001b[39m.\u001b[39miloc[item, \u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mAugmented/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(AugmentType))\n\u001b[1;32m--> 100\u001b[0m     signal, sample_rate \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39;49mload(\n\u001b[0;32m    101\u001b[0m         newAugment, sr\u001b[39m=\u001b[39;49mSAMPLE_RATE)\n\u001b[0;32m    102\u001b[0m     mfcc \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39mfeature\u001b[39m.\u001b[39mmfcc(\n\u001b[0;32m    103\u001b[0m         y\u001b[39m=\u001b[39msignal, sr\u001b[39m=\u001b[39mSAMPLE_RATE, n_mfcc\u001b[39m=\u001b[39mnum_mfcc, n_fft\u001b[39m=\u001b[39mn_fft, hop_length\u001b[39m=\u001b[39mhop_length)\n\u001b[0;32m    104\u001b[0m     mfcc \u001b[39m=\u001b[39m mfcc\u001b[39m.\u001b[39mT\n",
      "File \u001b[1;32me:\\TA-Bill\\venv\\lib\\site-packages\\librosa\\util\\decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     91\u001b[0m args_msg \u001b[39m=\u001b[39m [\n\u001b[0;32m     92\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[0;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[39m-\u001b[39mextra_args:])\n\u001b[0;32m     94\u001b[0m ]\n",
      "File \u001b[1;32me:\\TA-Bill\\venv\\lib\\site-packages\\librosa\\core\\audio.py:170\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, (\u001b[39mstr\u001b[39m, pathlib\u001b[39m.\u001b[39mPurePath)):\n\u001b[0;32m    169\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[39m\"\u001b[39m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m--> 170\u001b[0m     y, sr_native \u001b[39m=\u001b[39m __audioread_load(path, offset, duration, dtype)\n\u001b[0;32m    171\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    172\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[1;32me:\\TA-Bill\\venv\\lib\\site-packages\\librosa\\core\\audio.py:226\u001b[0m, in \u001b[0;36m__audioread_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    223\u001b[0m     reader \u001b[39m=\u001b[39m path\n\u001b[0;32m    224\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    225\u001b[0m     \u001b[39m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m     reader \u001b[39m=\u001b[39m audioread\u001b[39m.\u001b[39;49maudio_open(path)\n\u001b[0;32m    228\u001b[0m \u001b[39mwith\u001b[39;00m reader \u001b[39mas\u001b[39;00m input_file:\n\u001b[0;32m    229\u001b[0m     sr_native \u001b[39m=\u001b[39m input_file\u001b[39m.\u001b[39msamplerate\n",
      "File \u001b[1;32me:\\TA-Bill\\venv\\lib\\site-packages\\audioread\\__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[39mfor\u001b[39;00m BackendClass \u001b[39min\u001b[39;00m backends:\n\u001b[0;32m    126\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[39mreturn\u001b[39;00m BackendClass(path)\n\u001b[0;32m    128\u001b[0m     \u001b[39mexcept\u001b[39;00m DecodeError:\n\u001b[0;32m    129\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32me:\\TA-Bill\\venv\\lib\\site-packages\\audioread\\rawread.py:59\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, filename):\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fh \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     61\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m aifc\u001b[39m.\u001b[39mopen(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fh)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/Augmented/AddGaussianNoise/1091_WSI_SAD_XX.wav'"
     ]
    }
   ],
   "source": [
    "crema_train_gaussian_value, crema_train_gaussian_target = turn_into_data_for_model(\n",
    "    train_df, test_df, 40, 2048, 512, AugmentType=\"AddGaussianNoise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crema_train_pitch_value, crema_train_pitch_target = turn_into_data_for_model(\n",
    "    train_df, test_df, 40, 2048, 512, AugmentType=\"PitchShift\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crema_train_timeStretch_value, crema_train_timeStretch_target = turn_into_data_for_model(\n",
    "    train_df, test_df, 40, 2048, 512, AugmentType=\"TimeStretch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
